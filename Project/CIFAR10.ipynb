{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 27 days\n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 27 days\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from scipy.ndimage.filters import convolve\n",
    "\n",
    "#note: this requires the starter code for the assignments!\n",
    "from common.plotting import plot_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix a bug in printing SVG\n",
    "if sys.platform == 'win32':\n",
    "    print \"Monkey-patching pydot\"\n",
    "    import pydot\n",
    "\n",
    "    def force_find_graphviz(graphviz_root):\n",
    "        binpath = os.path.join(graphviz_root, 'bin')\n",
    "        programs = 'dot twopi neato circo fdp sfdp'\n",
    "        def helper():\n",
    "            for prg in programs.split():\n",
    "                if os.path.exists(os.path.join(binpath, prg)):\n",
    "                    yield ((prg, os.path.join(binpath, prg)))\n",
    "                elif os.path.exists(os.path.join(binpath, prg+'.exe')):\n",
    "                    yield ((prg, os.path.join(binpath, prg+'.exe')))\n",
    "        progdict = dict(helper())\n",
    "        return lambda: progdict\n",
    "\n",
    "    pydot.find_graphviz = force_find_graphviz('c:/Program Files (x86)/Graphviz2.34/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor.signal.downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "def svgdotprint(g):\n",
    "    return SVG(theano.printing.pydotprint(g, return_image=True, format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.745434 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in xrange(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theano.config.optimizer = 'fast_compile'\n",
    "theano.config.exception_verbosity = 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuel.datasets.cifar10 import CIFAR10\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "\n",
    "CIFAR10.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}))\n",
    "\n",
    "cifar10_train = CIFAR10((\"train\",), subset=slice(None,40000))\n",
    "#this stream will shuffle the CIFAR10 set and return us batches of 100 examples\n",
    "cifar10_train_stream = DataStream.default_stream(\n",
    "    cifar10_train,\n",
    "    iteration_scheme=ShuffledScheme(cifar10_train.num_examples, 25))\n",
    "                                               \n",
    "cifar10_validation = CIFAR10((\"train\",), subset=slice(40000, None))\n",
    "\n",
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "cifar10_validation_stream = DataStream.default_stream(\n",
    "    cifar10_validation, iteration_scheme=SequentialScheme(cifar10_validation.num_examples, 100))\n",
    "cifar10_test = CIFAR10((\"test\",))\n",
    "cifar10_test_stream = DataStream.default_stream(\n",
    "    cifar10_test, iteration_scheme=SequentialScheme(cifar10_test.num_examples, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing (u'features', u'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (25, 3, 32, 32) containing float32\n",
      " - an array of size (25, 1) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (100, 3, 32, 32) containing float32\n",
      " - an array of size (100, 1) containing uint8\n"
     ]
    }
   ],
   "source": [
    "print \"The streams return batches containing %s\" % (cifar10_train_stream.sources,)\n",
    "\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(cifar10_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "    \n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(cifar10_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# A theano variable is an entry to the cmputational graph\n",
    "# We will need to provide its value during function call\n",
    "# X is batch_size x num_channels x img_rows x img_columns\n",
    "X = theano.tensor.tensor4('X')\n",
    "\n",
    "# Y is 1D, it lists the targets for all examples\n",
    "Y = theano.tensor.matrix('Y', dtype='uint8')\n",
    "\n",
    "#The tag values are useful during debugging the creation of Theano graphs\n",
    "\n",
    "X_test_value, Y_test_value = next(cifar10_train_stream.get_epoch_iterator())\n",
    "#\n",
    "# Unfortunately, test tags don't work with convolutions with newest Theano :(\n",
    "#\n",
    "theano.config.compute_test_value = 'off' # Enable the computation of test values\n",
    "\n",
    "\n",
    "X.tag.test_value = X_test_value[:3]\n",
    "Y.tag.test_value = Y_test_value[:3]\n",
    "\n",
    "print \"X shape: %s\" % (X.tag.test_value.shape,)\n",
    "\n",
    "# this list will hold all parameters of the network\n",
    "model_parameters = []\n",
    "\n",
    "#The first convolutional layer\n",
    "#The shape is: num_out_filters x num_in_filters x filter_height x filter_width\n",
    "num_filters_1 = 40 #we will apply that many convolution filters in the first layer\n",
    "CW1 = theano.shared(np.zeros((num_filters_1,3,5,5), dtype='float32'),\n",
    "                   name='CW1')\n",
    "#please note - this is somewhat non-standard\n",
    "CW1.tag.initializer = IsotropicGaussian(0.04)\n",
    "\n",
    "CB1 = theano.shared(np.zeros((num_filters_1,), dtype='float32'),\n",
    "                    name='CB1')\n",
    "CB1.tag.initializer = Constant(0.0)\n",
    "model_parameters += [CW1, CB1]\n",
    "\n",
    "after_C1 = theano.tensor.maximum(\n",
    "    0.0,\n",
    "    theano.tensor.nnet.conv2d(X, CW1) + CB1.dimshuffle('x',0,'x','x')\n",
    "    )\n",
    "# print \"after_C1 shape: %s\" % (after_C1.tag.test_value.shape,)\n",
    "after_P1 = theano.tensor.signal.downsample.max_pool_2d(after_C1, (2,2), ignore_border=True)\n",
    "# print \"after_P1 shape: %s\" % (after_P1.tag.test_value.shape,)\n",
    "\n",
    "# ## _______________________\n",
    "\n",
    "# num_filters_1A = 13 #we will apply that many convolution filters in the first layer\n",
    "# CW1A = theano.shared(np.zeros((num_filters_1A,num_filters_1,5,5), dtype='float32'),\n",
    "#                    name='CW1A')\n",
    "# #please note - this is somewhat non-standard\n",
    "# CW1A.tag.initializer = IsotropicGaussian(0.04)\n",
    "\n",
    "# CB1A = theano.shared(np.zeros((num_filters_1A,), dtype='float32'),\n",
    "#                     name='CB1A')\n",
    "# CB1A.tag.initializer = Constant(0.0)\n",
    "# model_parameters += [CW1A, CB1A]\n",
    "\n",
    "# after_C1A = theano.tensor.maximum(\n",
    "#     0.0,\n",
    "#     theano.tensor.nnet.conv2d(after_P1, CW1A) + CB1A.dimshuffle('x',0,'x','x')\n",
    "#     )\n",
    "# # print \"after_C1 shape: %s\" % (after_C1.tag.test_value.shape,)\n",
    "# after_P1A = theano.tensor.signal.downsample.max_pool_2d(after_C1A, (2,2), ignore_border=True)\n",
    "# # print \"after_P1 shape: %s\" % (after_P1.tag.test_value.shape,)\n",
    "\n",
    "# ## _______________________\n",
    "\n",
    "num_filters_2 = 300 #we will compute ten convolution filters in the first layer\n",
    "CW2 = theano.shared(np.zeros((num_filters_2,num_filters_1,5,5), dtype='float32'),\n",
    "                   name='CW2')\n",
    "CW2.tag.initializer = IsotropicGaussian(0.04)\n",
    "\n",
    "CB2 = theano.shared(np.zeros((num_filters_2,), dtype='float32'),\n",
    "                    name='CB2')\n",
    "CB2.tag.initializer = Constant(0.0)\n",
    "model_parameters += [CW2, CB2]\n",
    "\n",
    "after_C2 = theano.tensor.maximum(\n",
    "    0.0,\n",
    "    theano.tensor.nnet.conv2d(after_P1, CW2) + CB2.dimshuffle('x',0,'x','x')\n",
    "    )\n",
    "# print \"after_C2 shape: %s\" % (after_C2.tag.test_value.shape,)\n",
    "after_P2 = theano.tensor.signal.downsample.max_pool_2d(after_C2, (2,2), ignore_border=True)\n",
    "# print \"after_P2 shape: %s\" % (after_P2.tag.test_value.shape,)\n",
    "\n",
    "#Fully connected layers - we just flatten all filter maps\n",
    "num_fw3_hidden=900\n",
    "FW3 = theano.shared(np.zeros((num_filters_2 * 5 * 5, num_fw3_hidden), dtype='float32'),\n",
    "                   name='FW3')\n",
    "FW3.tag.initializer = IsotropicGaussian(0.04)\n",
    "\n",
    "FB3 = theano.shared(np.zeros((num_fw3_hidden,), dtype='float32'),\n",
    "                    name='FB3')\n",
    "FB3.tag.initializer = Constant(0.0)\n",
    "model_parameters += [FW3, FB3]\n",
    "\n",
    "after_F3 = theano.tensor.maximum(0.0, \n",
    "                                 theano.tensor.dot(after_P2.flatten(2), FW3) + FB3.dimshuffle('x',0))\n",
    "# print \"after_F3 shape: %s\" % (after_F3.tag.test_value.shape,)\n",
    "\n",
    "\n",
    "num_fw4_hidden=40\n",
    "FW4 = theano.shared(np.zeros((num_fw3_hidden, num_fw4_hidden), dtype='float32'),\n",
    "                   name='FW4')\n",
    "FW4.tag.initializer = IsotropicGaussian(0.04)\n",
    "\n",
    "FB4 = theano.shared(np.zeros((num_fw4_hidden,), dtype='float32'),\n",
    "                    name='FB4')\n",
    "FB4.tag.initializer = Constant(0.0)\n",
    "model_parameters += [FW4, FB4]\n",
    "\n",
    "after_F4 = theano.tensor.dot(after_F3, FW4) + FB4.dimshuffle('x',0)\n",
    "# print \"after_F4 shape: %s\" % (after_F4.tag.test_value.shape,)\n",
    "\n",
    "log_probs = theano.tensor.nnet.softmax(after_F4)\n",
    "\n",
    "predictions = theano.tensor.argmax(log_probs, axis=1)\n",
    "\n",
    "error_rate = theano.tensor.neq(predictions,Y.ravel()).mean()\n",
    "nll = - theano.tensor.log(log_probs[theano.tensor.arange(Y.shape[0]), Y.ravel()]).mean()\n",
    "\n",
    "weight_decay = 0.0\n",
    "for p in model_parameters:\n",
    "    if p.name[1]=='W':\n",
    "        weight_decay = weight_decay + 3e-3 * (p**2).sum()\n",
    "\n",
    "cost = nll + weight_decay\n",
    "\n",
    "#At this point stop computing test values\n",
    "theano.config.compute_test_value = 'off' # Enable the computation of test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# We have built a computation graph for computing the error_rate, predictions and cost\n",
    "#\n",
    "# svgdotprint(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The updates will update our shared values\n",
    "updates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrate = theano.tensor.scalar('lrate',dtype='float32')\n",
    "momentum = theano.tensor.scalar('momentum',dtype='float32')\n",
    "\n",
    "# Theano will compute the gradients for us\n",
    "gradients = theano.grad(cost, model_parameters)\n",
    "\n",
    "#initialize storage for momentum\n",
    "velocities = [theano.shared(np.zeros_like(p.get_value()), name='V_%s' %(p.name, )) for p in model_parameters]\n",
    "\n",
    "for p,g,v in zip(model_parameters, gradients, velocities):\n",
    "    v_new = momentum * v - lrate * g\n",
    "    p_new = p + v_new\n",
    "    updates += [(v,v_new), (p, p_new)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(V_CW1, Elemwise{sub,no_inplace}.0),\n",
       " (CW1, Elemwise{add,no_inplace}.0),\n",
       " (V_CB1, Elemwise{sub,no_inplace}.0),\n",
       " (CB1, Elemwise{add,no_inplace}.0),\n",
       " (V_CW2, Elemwise{sub,no_inplace}.0),\n",
       " (CW2, Elemwise{add,no_inplace}.0),\n",
       " (V_CB2, Elemwise{sub,no_inplace}.0),\n",
       " (CB2, Elemwise{add,no_inplace}.0),\n",
       " (V_FW3, Elemwise{sub,no_inplace}.0),\n",
       " (FW3, Elemwise{add,no_inplace}.0),\n",
       " (V_FB3, Elemwise{sub,no_inplace}.0),\n",
       " (FB3, Elemwise{add,no_inplace}.0),\n",
       " (V_FW4, Elemwise{sub,no_inplace}.0),\n",
       " (FW4, Elemwise{add,no_inplace}.0),\n",
       " (V_FB4, Elemwise{sub,no_inplace}.0),\n",
       " (FB4, Elemwise{add,no_inplace}.0)]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile theano functions\n",
    "\n",
    "#each call to train step will make one SGD step\n",
    "train_step = theano.function([X,Y,lrate,momentum],[cost, error_rate, nll, weight_decay],updates=updates)\n",
    "#each call to predict will return predictions on a batch of data\n",
    "predict = theano.function([X], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(stream):\n",
    "    errs = 0.0\n",
    "    num_samples = 0.0\n",
    "    for X, Y in stream.get_epoch_iterator():\n",
    "        errs += (predict(X)!=Y.ravel()).sum()\n",
    "        num_samples += Y.shape[0]\n",
    "    return errs/num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#utilities to save values of parameters and to load them\n",
    "\n",
    "def init_parameters():\n",
    "    rng = np.random.RandomState(1234)\n",
    "    for p in model_parameters:\n",
    "        p.set_value(p.tag.initializer.generate(rng, p.get_value().shape))\n",
    "\n",
    "def snapshot_parameters():\n",
    "    return [p.get_value(borrow=False) for p in model_parameters]\n",
    "\n",
    "def load_parameters(snapshot):\n",
    "    for p, s in zip(model_parameters, snapshot):\n",
    "        p.set_value(s, borrow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init training\n",
    "\n",
    "i=0\n",
    "e=0\n",
    "\n",
    "init_parameters()\n",
    "for v in velocities:\n",
    "    v.set_value(np.zeros_like(v.get_value()))\n",
    "\n",
    "best_valid_error_rate = np.inf\n",
    "best_params = snapshot_parameters()\n",
    "best_params_epoch = 0\n",
    "\n",
    "train_erros = []\n",
    "train_loss = []\n",
    "train_nll = []\n",
    "validation_errors = []\n",
    "\n",
    "number_of_epochs = 3\n",
    "patience_expansion = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At minibatch 100, batch loss 30.104431, batch nll 2.019913, batch error rate 88.000000%\n",
      "At minibatch 200, batch loss 24.270510, batch nll 1.616426, batch error rate 52.000000%\n",
      "At minibatch 300, batch loss 19.793594, batch nll 1.508840, batch error rate 52.000000%\n",
      "At minibatch 400, batch loss 16.641531, batch nll 1.873466, batch error rate 68.000000%\n",
      "At minibatch 500, batch loss 13.417565, batch nll 1.476010, batch error rate 64.000000%\n",
      "At minibatch 600, batch loss 11.586579, batch nll 1.916233, batch error rate 52.000000%\n",
      "At minibatch 700, batch loss 9.210996, batch nll 1.366899, batch error rate 48.000000%\n",
      "At minibatch 800, batch loss 7.818548, batch nll 1.441252, batch error rate 52.000000%\n",
      "At minibatch 900, batch loss 6.970055, batch nll 1.765708, batch error rate 52.000000%\n",
      "At minibatch 1000, batch loss 5.661194, batch nll 1.401702, batch error rate 52.000000%\n",
      "At minibatch 1100, batch loss 5.034337, batch nll 1.542571, batch error rate 44.000000%\n",
      "At minibatch 1200, batch loss 4.228468, batch nll 1.340630, batch error rate 52.000000%\n",
      "At minibatch 1300, batch loss 3.879313, batch nll 1.484474, batch error rate 52.000000%\n",
      "At minibatch 1400, batch loss 3.220140, batch nll 1.216449, batch error rate 48.000000%\n",
      "At minibatch 1500, batch loss 3.034901, batch nll 1.348474, batch error rate 36.000000%\n",
      "At minibatch 1600, batch loss 2.341001, batch nll 0.908534, batch error rate 44.000000%\n",
      "After epoch 1: valid_err_rate: 47.330000% currently going to do 3 epochs\n",
      "After epoch 1: averaged train_err_rate: 54.862500% averaged train nll: 1.542139 averaged train loss: 11.469779\n",
      "At minibatch 1700, batch loss 2.189043, batch nll 0.954002, batch error rate 28.000000%\n",
      "At minibatch 1800, batch loss 2.064837, batch nll 0.983417, batch error rate 32.000000%\n",
      "At minibatch 1900, batch loss 2.512204, batch nll 1.556748, batch error rate 48.000000%\n",
      "At minibatch 2000, batch loss 1.738487, batch nll 0.881540, batch error rate 16.000000%\n",
      "At minibatch 2100, batch loss 1.659454, batch nll 0.885894, batch error rate 32.000000%\n",
      "At minibatch 2200, batch loss 1.955774, batch nll 1.248493, batch error rate 44.000000%\n",
      "At minibatch 2300, batch loss 2.088153, batch nll 1.430396, batch error rate 52.000000%\n",
      "At minibatch 2400, batch loss 2.277290, batch nll 1.664009, batch error rate 60.000000%\n",
      "At minibatch 2500, batch loss 1.900085, batch nll 1.313922, batch error rate 40.000000%\n",
      "At minibatch 2600, batch loss 1.665991, batch nll 1.109581, batch error rate 40.000000%\n",
      "At minibatch 2700, batch loss 1.636145, batch nll 1.101122, batch error rate 44.000000%\n",
      "At minibatch 2800, batch loss 1.843647, batch nll 1.329718, batch error rate 44.000000%\n",
      "At minibatch 2900, batch loss 1.727611, batch nll 1.229061, batch error rate 32.000000%\n",
      "At minibatch 3000, batch loss 1.710175, batch nll 1.226453, batch error rate 52.000000%\n",
      "At minibatch 3100, batch loss 2.008740, batch nll 1.530769, batch error rate 60.000000%\n",
      "At minibatch 3200, batch loss 1.477427, batch nll 1.005909, batch error rate 40.000000%\n",
      "After epoch 2: valid_err_rate: 42.870000% currently going to do 4 epochs\n",
      "After epoch 2: averaged train_err_rate: 44.562500% averaged train nll: 1.265931 averaged train loss: 1.982366\n",
      "At minibatch 3300, batch loss 1.852195, batch nll 1.376441, batch error rate 56.000000%\n",
      "At minibatch 3400, batch loss 1.128261, batch nll 0.651900, batch error rate 8.000000%\n",
      "At minibatch 3500, batch loss 2.021898, batch nll 1.541265, batch error rate 44.000000%\n",
      "At minibatch 3600, batch loss 1.702370, batch nll 1.223921, batch error rate 36.000000%\n",
      "At minibatch 3700, batch loss 1.547444, batch nll 1.068650, batch error rate 32.000000%\n",
      "At minibatch 3800, batch loss 1.802222, batch nll 1.321159, batch error rate 52.000000%\n",
      "At minibatch 3900, batch loss 1.379406, batch nll 0.903714, batch error rate 32.000000%\n",
      "At minibatch 4000, batch loss 1.585201, batch nll 1.107947, batch error rate 48.000000%\n",
      "At minibatch 4100, batch loss 1.794275, batch nll 1.315957, batch error rate 52.000000%\n",
      "At minibatch 4200, batch loss 1.764988, batch nll 1.289590, batch error rate 36.000000%\n",
      "At minibatch 4300, batch loss 1.490109, batch nll 1.019088, batch error rate 36.000000%\n",
      "At minibatch 4400, batch loss 1.400290, batch nll 0.923719, batch error rate 36.000000%\n",
      "At minibatch 4500, batch loss 1.721704, batch nll 1.246805, batch error rate 40.000000%\n",
      "At minibatch 4600, batch loss 1.647579, batch nll 1.177233, batch error rate 40.000000%\n",
      "At minibatch 4700, batch loss 1.599705, batch nll 1.130387, batch error rate 44.000000%\n",
      "At minibatch 4800, batch loss 1.892354, batch nll 1.415860, batch error rate 52.000000%\n",
      "After epoch 3: valid_err_rate: 41.600000% currently going to do 5 epochs\n",
      "After epoch 3: averaged train_err_rate: 41.325000% averaged train nll: 1.187468 averaged train loss: 1.663987\n",
      "At minibatch 4900, batch loss 1.702506, batch nll 1.221414, batch error rate 48.000000%\n",
      "At minibatch 5000, batch loss 1.334580, batch nll 0.849409, batch error rate 52.000000%\n",
      "At minibatch 5100, batch loss 1.643119, batch nll 1.150898, batch error rate 44.000000%\n",
      "At minibatch 5200, batch loss 1.580908, batch nll 1.091070, batch error rate 44.000000%\n",
      "At minibatch 5300, batch loss 1.991950, batch nll 1.504717, batch error rate 40.000000%\n",
      "At minibatch 5400, batch loss 1.448511, batch nll 0.954162, batch error rate 32.000000%\n",
      "At minibatch 5500, batch loss 1.307012, batch nll 0.812939, batch error rate 24.000000%\n",
      "At minibatch 5600, batch loss 1.706029, batch nll 1.212412, batch error rate 40.000000%\n",
      "At minibatch 5700, batch loss 1.819651, batch nll 1.331703, batch error rate 48.000000%\n",
      "At minibatch 5800, batch loss 1.105081, batch nll 0.619795, batch error rate 16.000000%\n",
      "At minibatch 5900, batch loss 1.380284, batch nll 0.894633, batch error rate 36.000000%\n",
      "At minibatch 6000, batch loss 1.663946, batch nll 1.177607, batch error rate 40.000000%\n",
      "At minibatch 6100, batch loss 1.929053, batch nll 1.446405, batch error rate 44.000000%\n",
      "At minibatch 6200, batch loss 1.387694, batch nll 0.902281, batch error rate 44.000000%\n",
      "At minibatch 6300, batch loss 1.953248, batch nll 1.465980, batch error rate 52.000000%\n",
      "At minibatch 6400, batch loss 1.418712, batch nll 0.933014, batch error rate 36.000000%\n",
      "After epoch 4: valid_err_rate: 38.870000% currently going to do 7 epochs\n",
      "After epoch 4: averaged train_err_rate: 39.387500% averaged train nll: 1.136132 averaged train loss: 1.623727\n",
      "At minibatch 6500, batch loss 1.308823, batch nll 0.806424, batch error rate 28.000000%\n",
      "At minibatch 6600, batch loss 2.039262, batch nll 1.531412, batch error rate 56.000000%\n",
      "At minibatch 6700, batch loss 1.425932, batch nll 0.916021, batch error rate 32.000000%\n",
      "At minibatch 6800, batch loss 1.953541, batch nll 1.447203, batch error rate 56.000000%\n",
      "At minibatch 6900, batch loss 1.616837, batch nll 1.110318, batch error rate 32.000000%\n",
      "At minibatch 7000, batch loss 2.020273, batch nll 1.513870, batch error rate 56.000000%\n",
      "At minibatch 7100, batch loss 1.368837, batch nll 0.865731, batch error rate 32.000000%\n",
      "At minibatch 7200, batch loss 1.448710, batch nll 0.939459, batch error rate 36.000000%\n",
      "At minibatch 7300, batch loss 1.424634, batch nll 0.921690, batch error rate 36.000000%\n",
      "At minibatch 7400, batch loss 1.923347, batch nll 1.420060, batch error rate 40.000000%\n",
      "At minibatch 7500, batch loss 2.041451, batch nll 1.536704, batch error rate 60.000000%\n",
      "At minibatch 7600, batch loss 1.141000, batch nll 0.634197, batch error rate 32.000000%\n",
      "At minibatch 7700, batch loss 1.715024, batch nll 1.210431, batch error rate 36.000000%\n",
      "At minibatch 7800, batch loss 2.015931, batch nll 1.520488, batch error rate 60.000000%\n",
      "At minibatch 7900, batch loss 1.505632, batch nll 1.009339, batch error rate 40.000000%\n",
      "At minibatch 8000, batch loss 1.346280, batch nll 0.853985, batch error rate 32.000000%\n",
      "After epoch 5: valid_err_rate: 43.860000% currently going to do 7 epochs\n",
      "After epoch 5: averaged train_err_rate: 39.087500% averaged train nll: 1.118434 averaged train loss: 1.621707\n",
      "At minibatch 8100, batch loss 1.596336, batch nll 1.094567, batch error rate 40.000000%\n",
      "At minibatch 8200, batch loss 1.755075, batch nll 1.249887, batch error rate 44.000000%\n",
      "At minibatch 8300, batch loss 1.619159, batch nll 1.104323, batch error rate 40.000000%\n",
      "At minibatch 8400, batch loss 1.307542, batch nll 0.785498, batch error rate 20.000000%\n",
      "At minibatch 8500, batch loss 1.834711, batch nll 1.311345, batch error rate 40.000000%\n",
      "At minibatch 8600, batch loss 1.433782, batch nll 0.910536, batch error rate 24.000000%\n",
      "At minibatch 8700, batch loss 1.656335, batch nll 1.134669, batch error rate 52.000000%\n",
      "At minibatch 8800, batch loss 1.541644, batch nll 1.020943, batch error rate 40.000000%\n",
      "At minibatch 8900, batch loss 1.407021, batch nll 0.892798, batch error rate 32.000000%\n",
      "At minibatch 9000, batch loss 1.276700, batch nll 0.759849, batch error rate 32.000000%\n",
      "At minibatch 9100, batch loss 1.801867, batch nll 1.281790, batch error rate 44.000000%\n",
      "At minibatch 9200, batch loss 1.497661, batch nll 0.984648, batch error rate 36.000000%\n",
      "At minibatch 9300, batch loss 1.552855, batch nll 1.047049, batch error rate 40.000000%\n",
      "At minibatch 9400, batch loss 1.617246, batch nll 1.110936, batch error rate 44.000000%\n",
      "At minibatch 9500, batch loss 1.968955, batch nll 1.467434, batch error rate 52.000000%\n",
      "At minibatch 9600, batch loss 1.580241, batch nll 1.079631, batch error rate 44.000000%\n",
      "After epoch 6: valid_err_rate: 39.660000% currently going to do 7 epochs\n",
      "After epoch 6: averaged train_err_rate: 38.390000% averaged train nll: 1.088249 averaged train loss: 1.601092\n",
      "At minibatch 9700, batch loss 1.590209, batch nll 1.079386, batch error rate 40.000000%\n",
      "At minibatch 9800, batch loss 1.801039, batch nll 1.286207, batch error rate 52.000000%\n",
      "At minibatch 9900, batch loss 1.994889, batch nll 1.476952, batch error rate 52.000000%\n",
      "At minibatch 10000, batch loss 1.669567, batch nll 1.146850, batch error rate 36.000000%\n",
      "At minibatch 10100, batch loss 1.226788, batch nll 0.712012, batch error rate 12.000000%\n",
      "At minibatch 10200, batch loss 1.355884, batch nll 0.837520, batch error rate 28.000000%\n",
      "At minibatch 10300, batch loss 2.171761, batch nll 1.653400, batch error rate 56.000000%\n",
      "At minibatch 10400, batch loss 1.523957, batch nll 1.012976, batch error rate 40.000000%\n",
      "At minibatch 10500, batch loss 1.655382, batch nll 1.142227, batch error rate 48.000000%\n",
      "At minibatch 10600, batch loss 1.606761, batch nll 1.094122, batch error rate 48.000000%\n",
      "At minibatch 10700, batch loss 1.505060, batch nll 0.996828, batch error rate 28.000000%\n",
      "At minibatch 10800, batch loss 1.670456, batch nll 1.168055, batch error rate 40.000000%\n",
      "At minibatch 10900, batch loss 1.761151, batch nll 1.263597, batch error rate 36.000000%\n",
      "At minibatch 11000, batch loss 1.417722, batch nll 0.927059, batch error rate 32.000000%\n",
      "At minibatch 11100, batch loss 1.387009, batch nll 0.893528, batch error rate 36.000000%\n",
      "At minibatch 11200, batch loss 1.900857, batch nll 1.407140, batch error rate 40.000000%\n",
      "After epoch 7: valid_err_rate: 36.420000% currently going to do 11 epochs\n",
      "After epoch 7: averaged train_err_rate: 37.675000% averaged train nll: 1.078896 averaged train loss: 1.588083\n",
      "At minibatch 11300, batch loss 1.156784, batch nll 0.661233, batch error rate 24.000000%\n",
      "At minibatch 11400, batch loss 1.877638, batch nll 1.381284, batch error rate 60.000000%\n",
      "At minibatch 11500, batch loss 1.679726, batch nll 1.181094, batch error rate 40.000000%\n",
      "At minibatch 11600, batch loss 1.578593, batch nll 1.083186, batch error rate 32.000000%\n",
      "At minibatch 11700, batch loss 1.540156, batch nll 1.041743, batch error rate 40.000000%\n",
      "At minibatch 11800, batch loss 1.430520, batch nll 0.931623, batch error rate 24.000000%\n",
      "At minibatch 11900, batch loss 1.146808, batch nll 0.645864, batch error rate 20.000000%\n",
      "At minibatch 12000, batch loss 1.343562, batch nll 0.845248, batch error rate 36.000000%\n",
      "At minibatch 12100, batch loss 1.511830, batch nll 1.014183, batch error rate 40.000000%\n",
      "At minibatch 12200, batch loss 1.631407, batch nll 1.137291, batch error rate 48.000000%\n",
      "At minibatch 12300, batch loss 1.604517, batch nll 1.117090, batch error rate 40.000000%\n",
      "At minibatch 12400, batch loss 1.584633, batch nll 1.102550, batch error rate 36.000000%\n",
      "At minibatch 12500, batch loss 1.293815, batch nll 0.812708, batch error rate 24.000000%\n",
      "At minibatch 12600, batch loss 1.525118, batch nll 1.047734, batch error rate 44.000000%\n",
      "At minibatch 12700, batch loss 1.819645, batch nll 1.341899, batch error rate 52.000000%\n",
      "At minibatch 12800, batch loss 1.516321, batch nll 1.039520, batch error rate 36.000000%\n",
      "After epoch 8: valid_err_rate: 36.160000% currently going to do 13 epochs\n",
      "After epoch 8: averaged train_err_rate: 35.365000% averaged train nll: 1.015919 averaged train loss: 1.507281\n",
      "At minibatch 12900, batch loss 1.844697, batch nll 1.364626, batch error rate 40.000000%\n",
      "At minibatch 13000, batch loss 1.392271, batch nll 0.904129, batch error rate 36.000000%\n",
      "At minibatch 13100, batch loss 1.264447, batch nll 0.773229, batch error rate 28.000000%\n",
      "At minibatch 13200, batch loss 1.560561, batch nll 1.071102, batch error rate 36.000000%\n",
      "At minibatch 13300, batch loss 1.650501, batch nll 1.158233, batch error rate 36.000000%\n",
      "At minibatch 13400, batch loss 1.226779, batch nll 0.735944, batch error rate 32.000000%\n",
      "At minibatch 13500, batch loss 1.037881, batch nll 0.553787, batch error rate 20.000000%\n",
      "At minibatch 13600, batch loss 1.690467, batch nll 1.210838, batch error rate 40.000000%\n",
      "At minibatch 13700, batch loss 1.260092, batch nll 0.780341, batch error rate 24.000000%\n",
      "At minibatch 13800, batch loss 1.618642, batch nll 1.141259, batch error rate 40.000000%\n",
      "At minibatch 13900, batch loss 1.305635, batch nll 0.826976, batch error rate 36.000000%\n",
      "At minibatch 14000, batch loss 1.574270, batch nll 1.103022, batch error rate 40.000000%\n",
      "At minibatch 14100, batch loss 1.545819, batch nll 1.071393, batch error rate 36.000000%\n",
      "At minibatch 14200, batch loss 1.257875, batch nll 0.786766, batch error rate 28.000000%\n",
      "At minibatch 14300, batch loss 1.531864, batch nll 1.062745, batch error rate 32.000000%\n",
      "At minibatch 14400, batch loss 1.190590, batch nll 0.721645, batch error rate 24.000000%\n",
      "After epoch 9: valid_err_rate: 32.880000% currently going to do 14 epochs\n",
      "After epoch 9: averaged train_err_rate: 33.927500% averaged train nll: 0.970499 averaged train loss: 1.450954\n",
      "At minibatch 14500, batch loss 1.239939, batch nll 0.764233, batch error rate 24.000000%\n",
      "At minibatch 14600, batch loss 1.276180, batch nll 0.798370, batch error rate 24.000000%\n",
      "At minibatch 14700, batch loss 1.682028, batch nll 1.201227, batch error rate 48.000000%\n",
      "At minibatch 14800, batch loss 1.390714, batch nll 0.903329, batch error rate 40.000000%\n",
      "At minibatch 14900, batch loss 1.785869, batch nll 1.299738, batch error rate 28.000000%\n",
      "At minibatch 15000, batch loss 1.600556, batch nll 1.115305, batch error rate 40.000000%\n",
      "At minibatch 15100, batch loss 1.123610, batch nll 0.640828, batch error rate 24.000000%\n",
      "At minibatch 15200, batch loss 1.565588, batch nll 1.088413, batch error rate 32.000000%\n",
      "At minibatch 15300, batch loss 1.286593, batch nll 0.812281, batch error rate 28.000000%\n",
      "At minibatch 15400, batch loss 1.585891, batch nll 1.114422, batch error rate 40.000000%\n",
      "At minibatch 15500, batch loss 1.274354, batch nll 0.804951, batch error rate 28.000000%\n",
      "At minibatch 15600, batch loss 1.432219, batch nll 0.961275, batch error rate 36.000000%\n",
      "At minibatch 15700, batch loss 1.378275, batch nll 0.908571, batch error rate 32.000000%\n",
      "At minibatch 15800, batch loss 1.437999, batch nll 0.970784, batch error rate 28.000000%\n",
      "At minibatch 15900, batch loss 1.309261, batch nll 0.843537, batch error rate 32.000000%\n",
      "At minibatch 16000, batch loss 2.091370, batch nll 1.623945, batch error rate 48.000000%\n",
      "After epoch 10: valid_err_rate: 34.100000% currently going to do 14 epochs\n",
      "After epoch 10: averaged train_err_rate: 32.065000% averaged train nll: 0.920201 averaged train loss: 1.395760\n",
      "At minibatch 16100, batch loss 1.143311, batch nll 0.673863, batch error rate 20.000000%\n",
      "At minibatch 16200, batch loss 1.122772, batch nll 0.646310, batch error rate 20.000000%\n",
      "At minibatch 16300, batch loss 1.363593, batch nll 0.887214, batch error rate 40.000000%\n",
      "At minibatch 16400, batch loss 1.354826, batch nll 0.880381, batch error rate 28.000000%\n",
      "At minibatch 16500, batch loss 1.280534, batch nll 0.806737, batch error rate 32.000000%\n",
      "At minibatch 16600, batch loss 1.296015, batch nll 0.824605, batch error rate 32.000000%\n",
      "At minibatch 16700, batch loss 1.740744, batch nll 1.271917, batch error rate 44.000000%\n",
      "At minibatch 16800, batch loss 1.268580, batch nll 0.799473, batch error rate 36.000000%\n",
      "At minibatch 16900, batch loss 1.079442, batch nll 0.611436, batch error rate 16.000000%\n",
      "At minibatch 17000, batch loss 1.431018, batch nll 0.961729, batch error rate 44.000000%\n",
      "At minibatch 17100, batch loss 1.209635, batch nll 0.741484, batch error rate 24.000000%\n",
      "At minibatch 17200, batch loss 1.318690, batch nll 0.853745, batch error rate 32.000000%\n",
      "At minibatch 17300, batch loss 1.248398, batch nll 0.785796, batch error rate 28.000000%\n",
      "At minibatch 17400, batch loss 1.639807, batch nll 1.177057, batch error rate 56.000000%\n",
      "At minibatch 17500, batch loss 2.157144, batch nll 1.694442, batch error rate 60.000000%\n",
      "At minibatch 17600, batch loss 1.654377, batch nll 1.193812, batch error rate 36.000000%\n",
      "After epoch 11: valid_err_rate: 33.030000% currently going to do 14 epochs\n",
      "After epoch 11: averaged train_err_rate: 31.037500% averaged train nll: 0.888104 averaged train loss: 1.356788\n",
      "At minibatch 17700, batch loss 1.687431, batch nll 1.221635, batch error rate 44.000000%\n",
      "At minibatch 17800, batch loss 1.049450, batch nll 0.580588, batch error rate 24.000000%\n",
      "At minibatch 17900, batch loss 1.565517, batch nll 1.093712, batch error rate 48.000000%\n",
      "At minibatch 18000, batch loss 1.674051, batch nll 1.201034, batch error rate 40.000000%\n",
      "At minibatch 18100, batch loss 1.143952, batch nll 0.670995, batch error rate 16.000000%\n",
      "At minibatch 18200, batch loss 1.171191, batch nll 0.700065, batch error rate 20.000000%\n",
      "At minibatch 18300, batch loss 1.172740, batch nll 0.700137, batch error rate 16.000000%\n",
      "At minibatch 18400, batch loss 1.538939, batch nll 1.065002, batch error rate 44.000000%\n",
      "At minibatch 18500, batch loss 1.778657, batch nll 1.308217, batch error rate 36.000000%\n",
      "At minibatch 18600, batch loss 1.351088, batch nll 0.881655, batch error rate 28.000000%\n",
      "At minibatch 18700, batch loss 1.375616, batch nll 0.906408, batch error rate 28.000000%\n",
      "At minibatch 18800, batch loss 1.093716, batch nll 0.625427, batch error rate 16.000000%\n",
      "At minibatch 18900, batch loss 1.148383, batch nll 0.681684, batch error rate 16.000000%\n",
      "At minibatch 19000, batch loss 1.238041, batch nll 0.774200, batch error rate 24.000000%\n",
      "At minibatch 19100, batch loss 1.449715, batch nll 0.987976, batch error rate 40.000000%\n",
      "At minibatch 19200, batch loss 1.267492, batch nll 0.807298, batch error rate 36.000000%\n",
      "After epoch 12: valid_err_rate: 30.340000% currently going to do 19 epochs\n",
      "After epoch 12: averaged train_err_rate: 29.585000% averaged train nll: 0.853226 averaged train loss: 1.321988\n",
      "At minibatch 19300, batch loss 1.585476, batch nll 1.120565, batch error rate 36.000000%\n",
      "At minibatch 19400, batch loss 1.180897, batch nll 0.713766, batch error rate 28.000000%\n",
      "At minibatch 19500, batch loss 1.295089, batch nll 0.824288, batch error rate 24.000000%\n",
      "At minibatch 19600, batch loss 1.006540, batch nll 0.533630, batch error rate 12.000000%\n",
      "At minibatch 19700, batch loss 1.007518, batch nll 0.534816, batch error rate 24.000000%\n",
      "At minibatch 19800, batch loss 1.254886, batch nll 0.780785, batch error rate 28.000000%\n",
      "At minibatch 19900, batch loss 1.076830, batch nll 0.601723, batch error rate 28.000000%\n",
      "At minibatch 20000, batch loss 1.436660, batch nll 0.966895, batch error rate 32.000000%\n",
      "At minibatch 20100, batch loss 1.632924, batch nll 1.165799, batch error rate 48.000000%\n",
      "At minibatch 20200, batch loss 1.155509, batch nll 0.687186, batch error rate 20.000000%\n",
      "At minibatch 20300, batch loss 1.395481, batch nll 0.925090, batch error rate 32.000000%\n",
      "At minibatch 20400, batch loss 1.370107, batch nll 0.903957, batch error rate 28.000000%\n",
      "At minibatch 20500, batch loss 1.335646, batch nll 0.872220, batch error rate 40.000000%\n",
      "At minibatch 20600, batch loss 1.415268, batch nll 0.953934, batch error rate 28.000000%\n",
      "At minibatch 20700, batch loss 1.206126, batch nll 0.749374, batch error rate 16.000000%\n",
      "At minibatch 20800, batch loss 1.525076, batch nll 1.067231, batch error rate 32.000000%\n",
      "After epoch 13: valid_err_rate: 30.970000% currently going to do 19 epochs\n",
      "After epoch 13: averaged train_err_rate: 28.630000% averaged train nll: 0.820943 averaged train loss: 1.288639\n",
      "At minibatch 20900, batch loss 1.026391, batch nll 0.565150, batch error rate 24.000000%\n",
      "At minibatch 21000, batch loss 1.116987, batch nll 0.652958, batch error rate 32.000000%\n",
      "At minibatch 21100, batch loss 1.212486, batch nll 0.744592, batch error rate 28.000000%\n",
      "At minibatch 21200, batch loss 1.022126, batch nll 0.553771, batch error rate 24.000000%\n",
      "At minibatch 21300, batch loss 1.185539, batch nll 0.715215, batch error rate 28.000000%\n",
      "At minibatch 21400, batch loss 1.387484, batch nll 0.916996, batch error rate 32.000000%\n",
      "At minibatch 21500, batch loss 1.274883, batch nll 0.807529, batch error rate 20.000000%\n",
      "At minibatch 21600, batch loss 1.182613, batch nll 0.713955, batch error rate 24.000000%\n",
      "At minibatch 21700, batch loss 1.329005, batch nll 0.861457, batch error rate 28.000000%\n",
      "At minibatch 21800, batch loss 1.141175, batch nll 0.674844, batch error rate 20.000000%\n",
      "At minibatch 21900, batch loss 1.216640, batch nll 0.752913, batch error rate 28.000000%\n",
      "At minibatch 22000, batch loss 1.106997, batch nll 0.646283, batch error rate 20.000000%\n",
      "At minibatch 22100, batch loss 1.208809, batch nll 0.746634, batch error rate 20.000000%\n",
      "At minibatch 22200, batch loss 1.113299, batch nll 0.650482, batch error rate 24.000000%\n",
      "At minibatch 22300, batch loss 1.423363, batch nll 0.961889, batch error rate 32.000000%\n",
      "At minibatch 22400, batch loss 1.219461, batch nll 0.759322, batch error rate 20.000000%\n",
      "After epoch 14: valid_err_rate: 30.770000% currently going to do 19 epochs\n",
      "After epoch 14: averaged train_err_rate: 27.385000% averaged train nll: 0.791421 averaged train loss: 1.256316\n",
      "At minibatch 22500, batch loss 1.203347, batch nll 0.739966, batch error rate 24.000000%\n",
      "At minibatch 22600, batch loss 1.211958, batch nll 0.747257, batch error rate 28.000000%\n",
      "At minibatch 22700, batch loss 1.251190, batch nll 0.780518, batch error rate 28.000000%\n",
      "At minibatch 22800, batch loss 1.032955, batch nll 0.557477, batch error rate 12.000000%\n",
      "At minibatch 22900, batch loss 1.151364, batch nll 0.676717, batch error rate 24.000000%\n",
      "At minibatch 23000, batch loss 1.071378, batch nll 0.595958, batch error rate 24.000000%\n",
      "At minibatch 23100, batch loss 1.243010, batch nll 0.767717, batch error rate 28.000000%\n",
      "At minibatch 23200, batch loss 1.566976, batch nll 1.093854, batch error rate 40.000000%\n",
      "At minibatch 23300, batch loss 1.159166, batch nll 0.685497, batch error rate 24.000000%\n",
      "At minibatch 23400, batch loss 0.962932, batch nll 0.491583, batch error rate 16.000000%\n",
      "At minibatch 23500, batch loss 1.409506, batch nll 0.941922, batch error rate 32.000000%\n",
      "At minibatch 23600, batch loss 1.032458, batch nll 0.564358, batch error rate 24.000000%\n",
      "At minibatch 23700, batch loss 1.355209, batch nll 0.889778, batch error rate 32.000000%\n",
      "At minibatch 23800, batch loss 1.254951, batch nll 0.791028, batch error rate 28.000000%\n",
      "At minibatch 23900, batch loss 1.101028, batch nll 0.639081, batch error rate 24.000000%\n",
      "At minibatch 24000, batch loss 1.040221, batch nll 0.579402, batch error rate 16.000000%\n",
      "After epoch 15: valid_err_rate: 30.970000% currently going to do 19 epochs\n",
      "After epoch 15: averaged train_err_rate: 26.647500% averaged train nll: 0.766240 averaged train loss: 1.235313\n",
      "At minibatch 24100, batch loss 0.960487, batch nll 0.494879, batch error rate 16.000000%\n",
      "At minibatch 24200, batch loss 1.109803, batch nll 0.643964, batch error rate 24.000000%\n",
      "At minibatch 24300, batch loss 0.850516, batch nll 0.383123, batch error rate 8.000000%\n",
      "At minibatch 24400, batch loss 1.407547, batch nll 0.938601, batch error rate 36.000000%\n",
      "At minibatch 24500, batch loss 1.023731, batch nll 0.554210, batch error rate 16.000000%\n",
      "At minibatch 24600, batch loss 1.265693, batch nll 0.794482, batch error rate 36.000000%\n",
      "At minibatch 24700, batch loss 1.562373, batch nll 1.090969, batch error rate 48.000000%\n",
      "At minibatch 24800, batch loss 1.152043, batch nll 0.681163, batch error rate 12.000000%\n",
      "At minibatch 24900, batch loss 1.418422, batch nll 0.946504, batch error rate 36.000000%\n",
      "At minibatch 25000, batch loss 1.091428, batch nll 0.618230, batch error rate 24.000000%\n",
      "At minibatch 25100, batch loss 1.405607, batch nll 0.936164, batch error rate 36.000000%\n",
      "At minibatch 25200, batch loss 1.157079, batch nll 0.690114, batch error rate 24.000000%\n",
      "At minibatch 25300, batch loss 1.104758, batch nll 0.638295, batch error rate 24.000000%\n",
      "At minibatch 25400, batch loss 1.341784, batch nll 0.876556, batch error rate 24.000000%\n",
      "At minibatch 25500, batch loss 1.323825, batch nll 0.859087, batch error rate 36.000000%\n",
      "At minibatch 25600, batch loss 0.933314, batch nll 0.470657, batch error rate 12.000000%\n",
      "After epoch 16: valid_err_rate: 27.340000% currently going to do 25 epochs\n",
      "After epoch 16: averaged train_err_rate: 25.512500% averaged train nll: 0.745123 averaged train loss: 1.213253\n",
      "At minibatch 25700, batch loss 1.353170, batch nll 0.887419, batch error rate 28.000000%\n",
      "At minibatch 25800, batch loss 1.216845, batch nll 0.749176, batch error rate 24.000000%\n",
      "At minibatch 25900, batch loss 1.183675, batch nll 0.713694, batch error rate 20.000000%\n",
      "At minibatch 26000, batch loss 1.142600, batch nll 0.673321, batch error rate 20.000000%\n",
      "At minibatch 26100, batch loss 0.936172, batch nll 0.466105, batch error rate 8.000000%\n",
      "At minibatch 26200, batch loss 1.140084, batch nll 0.667664, batch error rate 28.000000%\n",
      "At minibatch 26300, batch loss 1.186219, batch nll 0.711409, batch error rate 28.000000%\n",
      "At minibatch 26400, batch loss 1.115039, batch nll 0.642414, batch error rate 24.000000%\n",
      "At minibatch 26500, batch loss 1.056762, batch nll 0.583041, batch error rate 24.000000%\n",
      "At minibatch 26600, batch loss 0.848439, batch nll 0.374893, batch error rate 8.000000%\n",
      "At minibatch 26700, batch loss 1.042858, batch nll 0.572190, batch error rate 20.000000%\n",
      "At minibatch 26800, batch loss 1.514091, batch nll 1.043428, batch error rate 36.000000%\n",
      "At minibatch 26900, batch loss 0.926354, batch nll 0.456911, batch error rate 12.000000%\n",
      "At minibatch 27000, batch loss 1.281407, batch nll 0.812809, batch error rate 32.000000%\n",
      "At minibatch 27100, batch loss 1.233517, batch nll 0.766103, batch error rate 28.000000%\n",
      "At minibatch 27200, batch loss 1.237869, batch nll 0.773519, batch error rate 16.000000%\n",
      "After epoch 17: valid_err_rate: 28.050000% currently going to do 25 epochs\n",
      "After epoch 17: averaged train_err_rate: 24.785000% averaged train nll: 0.719055 averaged train loss: 1.188992\n",
      "At minibatch 27300, batch loss 1.191384, batch nll 0.721259, batch error rate 24.000000%\n",
      "At minibatch 27400, batch loss 1.154963, batch nll 0.681541, batch error rate 24.000000%\n",
      "At minibatch 27500, batch loss 1.406297, batch nll 0.932189, batch error rate 32.000000%\n",
      "At minibatch 27600, batch loss 0.886788, batch nll 0.411377, batch error rate 16.000000%\n",
      "At minibatch 27700, batch loss 0.762409, batch nll 0.284739, batch error rate 4.000000%\n",
      "At minibatch 27800, batch loss 1.125277, batch nll 0.645391, batch error rate 20.000000%\n",
      "At minibatch 27900, batch loss 0.985477, batch nll 0.505801, batch error rate 16.000000%\n",
      "At minibatch 28000, batch loss 1.432161, batch nll 0.953948, batch error rate 40.000000%\n",
      "At minibatch 28100, batch loss 1.089686, batch nll 0.610431, batch error rate 16.000000%\n",
      "At minibatch 28200, batch loss 1.091977, batch nll 0.615069, batch error rate 20.000000%\n",
      "At minibatch 28300, batch loss 1.243166, batch nll 0.767916, batch error rate 36.000000%\n",
      "At minibatch 28400, batch loss 1.126042, batch nll 0.650396, batch error rate 24.000000%\n",
      "At minibatch 28500, batch loss 1.343388, batch nll 0.869238, batch error rate 20.000000%\n",
      "At minibatch 28600, batch loss 1.309074, batch nll 0.837102, batch error rate 36.000000%\n",
      "At minibatch 28700, batch loss 1.134386, batch nll 0.665784, batch error rate 24.000000%\n",
      "At minibatch 28800, batch loss 1.084444, batch nll 0.617146, batch error rate 36.000000%\n",
      "After epoch 18: valid_err_rate: 28.030000% currently going to do 25 epochs\n",
      "After epoch 18: averaged train_err_rate: 24.137500% averaged train nll: 0.693988 averaged train loss: 1.168823\n",
      "At minibatch 28900, batch loss 1.122358, batch nll 0.651346, batch error rate 28.000000%\n",
      "At minibatch 29000, batch loss 1.340583, batch nll 0.866948, batch error rate 36.000000%\n",
      "At minibatch 29100, batch loss 0.970360, batch nll 0.495149, batch error rate 16.000000%\n",
      "At minibatch 29200, batch loss 0.991112, batch nll 0.514476, batch error rate 20.000000%\n",
      "At minibatch 29300, batch loss 1.359255, batch nll 0.882832, batch error rate 24.000000%\n",
      "At minibatch 29400, batch loss 1.175169, batch nll 0.697889, batch error rate 24.000000%\n",
      "At minibatch 29500, batch loss 1.056290, batch nll 0.577911, batch error rate 24.000000%\n",
      "At minibatch 29600, batch loss 0.922553, batch nll 0.444389, batch error rate 8.000000%\n",
      "At minibatch 29700, batch loss 1.003022, batch nll 0.526236, batch error rate 16.000000%\n",
      "At minibatch 29800, batch loss 1.272909, batch nll 0.796502, batch error rate 24.000000%\n",
      "At minibatch 29900, batch loss 1.103216, batch nll 0.626604, batch error rate 24.000000%\n",
      "At minibatch 30000, batch loss 1.049196, batch nll 0.573160, batch error rate 16.000000%\n",
      "At minibatch 30100, batch loss 1.021048, batch nll 0.547913, batch error rate 12.000000%\n",
      "At minibatch 30200, batch loss 1.022087, batch nll 0.551525, batch error rate 20.000000%\n",
      "At minibatch 30300, batch loss 1.094333, batch nll 0.624289, batch error rate 24.000000%\n",
      "At minibatch 30400, batch loss 1.461819, batch nll 0.992907, batch error rate 44.000000%\n",
      "After epoch 19: valid_err_rate: 27.260000% currently going to do 29 epochs\n",
      "After epoch 19: averaged train_err_rate: 23.197500% averaged train nll: 0.672886 averaged train loss: 1.147399\n",
      "At minibatch 30500, batch loss 1.055409, batch nll 0.581643, batch error rate 20.000000%\n",
      "At minibatch 30600, batch loss 1.213725, batch nll 0.737281, batch error rate 28.000000%\n",
      "At minibatch 30700, batch loss 0.988176, batch nll 0.508862, batch error rate 16.000000%\n",
      "At minibatch 30800, batch loss 1.038481, batch nll 0.558438, batch error rate 20.000000%\n",
      "At minibatch 30900, batch loss 0.922031, batch nll 0.440240, batch error rate 8.000000%\n",
      "At minibatch 31000, batch loss 1.299111, batch nll 0.815833, batch error rate 36.000000%\n",
      "At minibatch 31100, batch loss 0.856518, batch nll 0.373530, batch error rate 8.000000%\n",
      "At minibatch 31200, batch loss 0.974215, batch nll 0.490355, batch error rate 16.000000%\n",
      "At minibatch 31300, batch loss 1.563415, batch nll 1.081125, batch error rate 40.000000%\n",
      "At minibatch 31400, batch loss 1.030048, batch nll 0.547326, batch error rate 16.000000%\n",
      "At minibatch 31500, batch loss 1.009805, batch nll 0.527741, batch error rate 20.000000%\n",
      "At minibatch 31600, batch loss 1.516606, batch nll 1.035337, batch error rate 44.000000%\n",
      "At minibatch 31700, batch loss 1.226003, batch nll 0.746728, batch error rate 36.000000%\n",
      "At minibatch 31800, batch loss 1.046026, batch nll 0.568817, batch error rate 16.000000%\n",
      "At minibatch 31900, batch loss 0.776449, batch nll 0.301248, batch error rate 8.000000%\n",
      "At minibatch 32000, batch loss 1.123837, batch nll 0.650463, batch error rate 16.000000%\n",
      "After epoch 20: valid_err_rate: 28.230000% currently going to do 29 epochs\n",
      "After epoch 20: averaged train_err_rate: 22.445000% averaged train nll: 0.658870 averaged train loss: 1.138460\n",
      "At minibatch 32100, batch loss 0.975362, batch nll 0.499326, batch error rate 20.000000%\n",
      "At minibatch 32200, batch loss 1.023126, batch nll 0.543735, batch error rate 24.000000%\n",
      "At minibatch 32300, batch loss 0.954022, batch nll 0.472943, batch error rate 16.000000%\n",
      "At minibatch 32400, batch loss 1.156403, batch nll 0.673363, batch error rate 28.000000%\n",
      "At minibatch 32500, batch loss 1.323934, batch nll 0.840906, batch error rate 32.000000%\n",
      "At minibatch 32600, batch loss 1.207086, batch nll 0.722504, batch error rate 32.000000%\n",
      "At minibatch 32700, batch loss 1.507100, batch nll 1.023662, batch error rate 40.000000%\n",
      "At minibatch 32800, batch loss 1.163545, batch nll 0.679920, batch error rate 28.000000%\n",
      "At minibatch 32900, batch loss 1.295944, batch nll 0.814401, batch error rate 36.000000%\n",
      "At minibatch 33000, batch loss 0.986767, batch nll 0.504954, batch error rate 20.000000%\n",
      "At minibatch 33100, batch loss 1.182365, batch nll 0.701181, batch error rate 12.000000%\n",
      "At minibatch 33200, batch loss 1.301965, batch nll 0.821944, batch error rate 28.000000%\n",
      "At minibatch 33300, batch loss 0.863185, batch nll 0.382876, batch error rate 4.000000%\n",
      "At minibatch 33400, batch loss 1.250215, batch nll 0.770839, batch error rate 24.000000%\n",
      "At minibatch 33500, batch loss 1.171587, batch nll 0.693933, batch error rate 20.000000%\n",
      "At minibatch 33600, batch loss 0.866791, batch nll 0.388908, batch error rate 8.000000%\n",
      "After epoch 21: valid_err_rate: 29.140000% currently going to do 29 epochs\n",
      "After epoch 21: averaged train_err_rate: 22.272500% averaged train nll: 0.643939 averaged train loss: 1.124644\n",
      "At minibatch 33700, batch loss 1.213797, batch nll 0.733768, batch error rate 28.000000%\n",
      "At minibatch 33800, batch loss 0.973724, batch nll 0.491078, batch error rate 12.000000%\n",
      "At minibatch 33900, batch loss 0.935917, batch nll 0.450629, batch error rate 20.000000%\n",
      "At minibatch 34000, batch loss 1.013773, batch nll 0.526988, batch error rate 24.000000%\n",
      "At minibatch 34100, batch loss 0.990298, batch nll 0.502976, batch error rate 20.000000%\n",
      "At minibatch 34200, batch loss 0.920449, batch nll 0.433434, batch error rate 12.000000%\n",
      "At minibatch 34300, batch loss 0.913563, batch nll 0.426763, batch error rate 16.000000%\n",
      "At minibatch 34400, batch loss 1.098751, batch nll 0.612630, batch error rate 16.000000%\n",
      "At minibatch 34500, batch loss 0.965995, batch nll 0.479368, batch error rate 20.000000%\n",
      "At minibatch 34600, batch loss 1.201906, batch nll 0.716383, batch error rate 24.000000%\n",
      "At minibatch 34700, batch loss 1.223165, batch nll 0.738268, batch error rate 28.000000%\n",
      "At minibatch 34800, batch loss 0.966269, batch nll 0.481504, batch error rate 20.000000%\n",
      "At minibatch 34900, batch loss 0.803510, batch nll 0.318342, batch error rate 12.000000%\n",
      "At minibatch 35000, batch loss 0.900361, batch nll 0.416090, batch error rate 8.000000%\n",
      "At minibatch 35100, batch loss 0.878450, batch nll 0.393770, batch error rate 16.000000%\n",
      "At minibatch 35200, batch loss 1.096910, batch nll 0.614396, batch error rate 24.000000%\n",
      "After epoch 22: valid_err_rate: 25.510000% currently going to do 34 epochs\n",
      "After epoch 22: averaged train_err_rate: 21.255000% averaged train nll: 0.619586 averaged train loss: 1.104435\n",
      "At minibatch 35300, batch loss 1.299553, batch nll 0.815553, batch error rate 24.000000%\n",
      "At minibatch 35400, batch loss 0.774913, batch nll 0.288230, batch error rate 8.000000%\n",
      "At minibatch 35500, batch loss 0.960471, batch nll 0.473065, batch error rate 12.000000%\n",
      "At minibatch 35600, batch loss 1.003507, batch nll 0.515006, batch error rate 8.000000%\n",
      "At minibatch 35700, batch loss 0.946316, batch nll 0.456596, batch error rate 12.000000%\n",
      "At minibatch 35800, batch loss 0.958135, batch nll 0.468119, batch error rate 16.000000%\n",
      "At minibatch 35900, batch loss 1.062214, batch nll 0.570715, batch error rate 8.000000%\n",
      "At minibatch 36000, batch loss 1.112496, batch nll 0.621125, batch error rate 28.000000%\n",
      "At minibatch 36100, batch loss 1.135526, batch nll 0.646481, batch error rate 28.000000%\n",
      "At minibatch 36200, batch loss 0.824655, batch nll 0.335323, batch error rate 12.000000%\n",
      "At minibatch 36300, batch loss 1.001326, batch nll 0.513475, batch error rate 20.000000%\n",
      "At minibatch 36400, batch loss 1.083427, batch nll 0.596204, batch error rate 20.000000%\n",
      "At minibatch 36500, batch loss 0.959750, batch nll 0.473504, batch error rate 8.000000%\n",
      "At minibatch 36600, batch loss 1.081410, batch nll 0.596453, batch error rate 20.000000%\n",
      "At minibatch 36700, batch loss 1.226285, batch nll 0.741803, batch error rate 24.000000%\n",
      "At minibatch 36800, batch loss 1.247795, batch nll 0.764132, batch error rate 28.000000%\n",
      "After epoch 23: valid_err_rate: 26.290000% currently going to do 34 epochs\n",
      "After epoch 23: averaged train_err_rate: 20.742500% averaged train nll: 0.606270 averaged train loss: 1.093824\n",
      "At minibatch 36900, batch loss 1.133331, batch nll 0.646792, batch error rate 20.000000%\n",
      "At minibatch 37000, batch loss 0.942672, batch nll 0.453889, batch error rate 16.000000%\n",
      "At minibatch 37100, batch loss 0.690395, batch nll 0.199979, batch error rate 4.000000%\n",
      "At minibatch 37200, batch loss 1.140830, batch nll 0.650157, batch error rate 24.000000%\n",
      "At minibatch 37300, batch loss 1.194356, batch nll 0.701977, batch error rate 20.000000%\n",
      "At minibatch 37400, batch loss 0.885778, batch nll 0.393844, batch error rate 16.000000%\n",
      "At minibatch 37500, batch loss 0.856296, batch nll 0.364009, batch error rate 12.000000%\n",
      "At minibatch 37600, batch loss 1.430842, batch nll 0.938319, batch error rate 36.000000%\n",
      "At minibatch 37700, batch loss 0.819637, batch nll 0.326558, batch error rate 4.000000%\n",
      "At minibatch 37800, batch loss 1.078848, batch nll 0.584728, batch error rate 16.000000%\n",
      "At minibatch 37900, batch loss 1.151501, batch nll 0.657458, batch error rate 24.000000%\n",
      "At minibatch 38000, batch loss 0.873247, batch nll 0.380023, batch error rate 8.000000%\n",
      "At minibatch 38100, batch loss 1.130237, batch nll 0.637097, batch error rate 24.000000%\n",
      "At minibatch 38200, batch loss 0.819173, batch nll 0.326687, batch error rate 8.000000%\n",
      "At minibatch 38300, batch loss 0.985815, batch nll 0.494087, batch error rate 20.000000%\n",
      "At minibatch 38400, batch loss 1.118166, batch nll 0.629314, batch error rate 20.000000%\n",
      "After epoch 24: valid_err_rate: 25.460000% currently going to do 37 epochs\n",
      "After epoch 24: averaged train_err_rate: 20.135000% averaged train nll: 0.587680 averaged train loss: 1.079242\n",
      "At minibatch 38500, batch loss 1.481222, batch nll 0.989856, batch error rate 32.000000%\n",
      "At minibatch 38600, batch loss 0.928734, batch nll 0.435917, batch error rate 16.000000%\n",
      "At minibatch 38700, batch loss 0.885711, batch nll 0.392758, batch error rate 8.000000%\n",
      "At minibatch 38800, batch loss 1.069080, batch nll 0.575848, batch error rate 16.000000%\n",
      "At minibatch 38900, batch loss 1.257313, batch nll 0.762782, batch error rate 16.000000%\n",
      "At minibatch 39000, batch loss 1.114202, batch nll 0.618404, batch error rate 32.000000%\n",
      "At minibatch 39100, batch loss 0.984126, batch nll 0.488079, batch error rate 20.000000%\n",
      "At minibatch 39200, batch loss 1.148165, batch nll 0.651206, batch error rate 16.000000%\n",
      "At minibatch 39300, batch loss 1.059772, batch nll 0.563267, batch error rate 24.000000%\n",
      "At minibatch 39400, batch loss 1.060887, batch nll 0.563960, batch error rate 16.000000%\n",
      "At minibatch 39500, batch loss 1.138088, batch nll 0.640823, batch error rate 20.000000%\n",
      "At minibatch 39600, batch loss 1.389502, batch nll 0.892742, batch error rate 24.000000%\n",
      "At minibatch 39700, batch loss 1.040636, batch nll 0.545510, batch error rate 24.000000%\n",
      "At minibatch 39800, batch loss 1.100264, batch nll 0.606145, batch error rate 24.000000%\n",
      "At minibatch 39900, batch loss 0.981610, batch nll 0.489252, batch error rate 20.000000%\n",
      "At minibatch 40000, batch loss 1.450975, batch nll 0.959287, batch error rate 32.000000%\n",
      "After epoch 25: valid_err_rate: 25.510000% currently going to do 37 epochs\n",
      "After epoch 25: averaged train_err_rate: 19.392500% averaged train nll: 0.573680 averaged train loss: 1.068375\n",
      "At minibatch 40100, batch loss 1.313074, batch nll 0.818169, batch error rate 32.000000%\n",
      "At minibatch 40200, batch loss 0.722737, batch nll 0.225370, batch error rate 12.000000%\n",
      "At minibatch 40300, batch loss 0.870921, batch nll 0.371559, batch error rate 12.000000%\n",
      "At minibatch 40400, batch loss 0.853097, batch nll 0.353551, batch error rate 8.000000%\n",
      "At minibatch 40500, batch loss 1.147825, batch nll 0.646463, batch error rate 12.000000%\n",
      "At minibatch 40600, batch loss 0.912250, batch nll 0.410885, batch error rate 20.000000%\n",
      "At minibatch 40700, batch loss 1.118963, batch nll 0.617156, batch error rate 16.000000%\n",
      "At minibatch 40800, batch loss 1.136360, batch nll 0.634688, batch error rate 24.000000%\n",
      "At minibatch 40900, batch loss 1.125183, batch nll 0.624423, batch error rate 20.000000%\n",
      "At minibatch 41000, batch loss 1.469193, batch nll 0.968918, batch error rate 32.000000%\n",
      "At minibatch 41100, batch loss 0.939193, batch nll 0.439115, batch error rate 16.000000%\n",
      "At minibatch 41200, batch loss 1.100952, batch nll 0.602109, batch error rate 20.000000%\n",
      "At minibatch 41300, batch loss 1.134867, batch nll 0.635920, batch error rate 24.000000%\n",
      "At minibatch 41400, batch loss 1.162630, batch nll 0.663776, batch error rate 24.000000%\n",
      "At minibatch 41500, batch loss 1.281065, batch nll 0.783297, batch error rate 28.000000%\n",
      "At minibatch 41600, batch loss 1.136767, batch nll 0.640125, batch error rate 24.000000%\n",
      "After epoch 26: valid_err_rate: 25.810000% currently going to do 37 epochs\n",
      "After epoch 26: averaged train_err_rate: 19.072500% averaged train nll: 0.558893 averaged train loss: 1.058078\n",
      "At minibatch 41700, batch loss 0.874342, batch nll 0.375504, batch error rate 12.000000%\n",
      "At minibatch 41800, batch loss 0.994408, batch nll 0.494145, batch error rate 20.000000%\n",
      "At minibatch 41900, batch loss 0.976729, batch nll 0.473760, batch error rate 8.000000%\n",
      "At minibatch 42000, batch loss 0.818426, batch nll 0.314760, batch error rate 16.000000%\n",
      "At minibatch 42100, batch loss 0.938739, batch nll 0.433637, batch error rate 16.000000%\n",
      "At minibatch 42200, batch loss 0.907748, batch nll 0.404312, batch error rate 20.000000%\n",
      "At minibatch 42300, batch loss 1.152639, batch nll 0.647853, batch error rate 28.000000%\n",
      "At minibatch 42400, batch loss 0.891076, batch nll 0.386769, batch error rate 4.000000%\n",
      "At minibatch 42500, batch loss 1.180932, batch nll 0.677135, batch error rate 28.000000%\n",
      "At minibatch 42600, batch loss 0.888956, batch nll 0.385878, batch error rate 20.000000%\n",
      "At minibatch 42700, batch loss 1.112545, batch nll 0.609178, batch error rate 20.000000%\n",
      "At minibatch 42800, batch loss 1.186437, batch nll 0.683426, batch error rate 24.000000%\n",
      "At minibatch 42900, batch loss 0.928287, batch nll 0.424727, batch error rate 8.000000%\n",
      "At minibatch 43000, batch loss 1.166797, batch nll 0.663917, batch error rate 24.000000%\n",
      "At minibatch 43100, batch loss 1.157743, batch nll 0.656301, batch error rate 32.000000%\n",
      "At minibatch 43200, batch loss 1.247030, batch nll 0.746297, batch error rate 32.000000%\n",
      "After epoch 27: valid_err_rate: 24.810000% currently going to do 41 epochs\n",
      "After epoch 27: averaged train_err_rate: 18.470000% averaged train nll: 0.546984 averaged train loss: 1.049704\n",
      "At minibatch 43300, batch loss 1.145606, batch nll 0.642667, batch error rate 20.000000%\n",
      "At minibatch 43400, batch loss 0.832633, batch nll 0.327317, batch error rate 4.000000%\n",
      "At minibatch 43500, batch loss 1.134230, batch nll 0.628012, batch error rate 16.000000%\n",
      "At minibatch 43600, batch loss 1.138798, batch nll 0.630433, batch error rate 28.000000%\n",
      "At minibatch 43700, batch loss 0.914289, batch nll 0.405494, batch error rate 20.000000%\n",
      "At minibatch 43800, batch loss 0.989726, batch nll 0.482405, batch error rate 12.000000%\n",
      "At minibatch 43900, batch loss 1.170768, batch nll 0.663763, batch error rate 36.000000%\n",
      "At minibatch 44000, batch loss 0.919309, batch nll 0.412244, batch error rate 12.000000%\n",
      "At minibatch 44100, batch loss 0.942578, batch nll 0.435417, batch error rate 8.000000%\n",
      "At minibatch 44200, batch loss 1.040404, batch nll 0.532729, batch error rate 16.000000%\n",
      "At minibatch 44300, batch loss 0.929939, batch nll 0.422027, batch error rate 12.000000%\n",
      "At minibatch 44400, batch loss 1.225484, batch nll 0.717818, batch error rate 24.000000%\n",
      "At minibatch 44500, batch loss 1.279990, batch nll 0.772457, batch error rate 28.000000%\n",
      "At minibatch 44600, batch loss 1.415379, batch nll 0.908917, batch error rate 24.000000%\n",
      "At minibatch 44700, batch loss 0.854716, batch nll 0.349890, batch error rate 12.000000%\n",
      "At minibatch 44800, batch loss 1.203104, batch nll 0.698581, batch error rate 24.000000%\n",
      "After epoch 28: valid_err_rate: 25.660000% currently going to do 41 epochs\n",
      "After epoch 28: averaged train_err_rate: 17.820000% averaged train nll: 0.525546 averaged train loss: 1.032149\n",
      "At minibatch 44900, batch loss 0.754367, batch nll 0.247329, batch error rate 8.000000%\n",
      "At minibatch 45000, batch loss 0.883864, batch nll 0.375106, batch error rate 12.000000%\n",
      "At minibatch 45100, batch loss 0.799769, batch nll 0.289984, batch error rate 0.000000%\n",
      "At minibatch 45200, batch loss 0.902841, batch nll 0.391475, batch error rate 12.000000%\n",
      "At minibatch 45300, batch loss 1.101455, batch nll 0.589284, batch error rate 24.000000%\n",
      "At minibatch 45400, batch loss 0.842250, batch nll 0.330271, batch error rate 8.000000%\n",
      "At minibatch 45500, batch loss 0.865098, batch nll 0.352625, batch error rate 8.000000%\n",
      "At minibatch 45600, batch loss 1.304220, batch nll 0.791872, batch error rate 20.000000%\n",
      "At minibatch 45700, batch loss 0.971613, batch nll 0.460294, batch error rate 12.000000%\n",
      "At minibatch 45800, batch loss 1.390220, batch nll 0.880116, batch error rate 28.000000%\n",
      "At minibatch 45900, batch loss 1.007374, batch nll 0.497667, batch error rate 16.000000%\n",
      "At minibatch 46000, batch loss 1.409205, batch nll 0.900364, batch error rate 32.000000%\n",
      "At minibatch 46100, batch loss 0.921975, batch nll 0.413822, batch error rate 12.000000%\n",
      "At minibatch 46200, batch loss 0.828218, batch nll 0.320275, batch error rate 12.000000%\n",
      "At minibatch 46300, batch loss 0.992624, batch nll 0.486259, batch error rate 24.000000%\n",
      "At minibatch 46400, batch loss 1.116310, batch nll 0.610342, batch error rate 24.000000%\n",
      "After epoch 29: valid_err_rate: 24.290000% currently going to do 44 epochs\n",
      "After epoch 29: averaged train_err_rate: 17.300000% averaged train nll: 0.511562 averaged train loss: 1.021167\n",
      "At minibatch 46500, batch loss 0.923524, batch nll 0.414297, batch error rate 8.000000%\n",
      "At minibatch 46600, batch loss 1.387142, batch nll 0.876529, batch error rate 40.000000%\n",
      "At minibatch 46700, batch loss 1.021240, batch nll 0.510450, batch error rate 20.000000%\n",
      "At minibatch 46800, batch loss 1.124558, batch nll 0.612263, batch error rate 20.000000%\n",
      "At minibatch 46900, batch loss 0.895137, batch nll 0.383346, batch error rate 16.000000%\n",
      "At minibatch 47000, batch loss 0.802366, batch nll 0.289460, batch error rate 4.000000%\n",
      "At minibatch 47100, batch loss 1.074943, batch nll 0.559886, batch error rate 24.000000%\n",
      "At minibatch 47200, batch loss 0.995473, batch nll 0.481443, batch error rate 16.000000%\n",
      "At minibatch 47300, batch loss 1.030829, batch nll 0.518137, batch error rate 20.000000%\n",
      "At minibatch 47400, batch loss 0.813703, batch nll 0.301614, batch error rate 8.000000%\n",
      "At minibatch 47500, batch loss 0.915708, batch nll 0.403820, batch error rate 16.000000%\n",
      "At minibatch 47600, batch loss 1.045188, batch nll 0.533567, batch error rate 20.000000%\n",
      "At minibatch 47700, batch loss 0.859126, batch nll 0.347479, batch error rate 12.000000%\n",
      "At minibatch 47800, batch loss 0.784764, batch nll 0.273958, batch error rate 4.000000%\n",
      "At minibatch 47900, batch loss 1.056603, batch nll 0.547503, batch error rate 20.000000%\n",
      "At minibatch 48000, batch loss 1.010063, batch nll 0.501510, batch error rate 12.000000%\n",
      "After epoch 30: valid_err_rate: 24.960000% currently going to do 44 epochs\n",
      "After epoch 30: averaged train_err_rate: 16.655000% averaged train nll: 0.498404 averaged train loss: 1.009882\n",
      "At minibatch 48100, batch loss 0.852312, batch nll 0.342182, batch error rate 12.000000%\n",
      "At minibatch 48200, batch loss 0.934041, batch nll 0.423089, batch error rate 12.000000%\n",
      "At minibatch 48300, batch loss 0.884742, batch nll 0.372705, batch error rate 8.000000%\n",
      "At minibatch 48400, batch loss 1.010785, batch nll 0.496495, batch error rate 16.000000%\n",
      "At minibatch 48500, batch loss 0.974201, batch nll 0.458963, batch error rate 20.000000%\n",
      "At minibatch 48600, batch loss 1.100447, batch nll 0.584474, batch error rate 8.000000%\n",
      "At minibatch 48700, batch loss 1.100881, batch nll 0.584602, batch error rate 20.000000%\n",
      "At minibatch 48800, batch loss 1.070657, batch nll 0.554507, batch error rate 12.000000%\n",
      "At minibatch 48900, batch loss 0.955266, batch nll 0.439387, batch error rate 16.000000%\n",
      "At minibatch 49000, batch loss 1.130531, batch nll 0.614832, batch error rate 24.000000%\n",
      "At minibatch 49100, batch loss 1.053407, batch nll 0.536188, batch error rate 24.000000%\n",
      "At minibatch 49200, batch loss 0.876381, batch nll 0.359434, batch error rate 4.000000%\n",
      "At minibatch 49300, batch loss 0.780460, batch nll 0.263893, batch error rate 4.000000%\n",
      "At minibatch 49400, batch loss 0.904715, batch nll 0.389197, batch error rate 12.000000%\n",
      "At minibatch 49500, batch loss 1.455869, batch nll 0.941154, batch error rate 36.000000%\n",
      "At minibatch 49600, batch loss 1.331856, batch nll 0.818654, batch error rate 28.000000%\n",
      "After epoch 31: valid_err_rate: 24.770000% currently going to do 44 epochs\n",
      "After epoch 31: averaged train_err_rate: 16.262500% averaged train nll: 0.490067 averaged train loss: 1.004729\n",
      "At minibatch 49700, batch loss 1.210889, batch nll 0.695024, batch error rate 24.000000%\n",
      "At minibatch 49800, batch loss 1.129362, batch nll 0.611721, batch error rate 24.000000%\n",
      "At minibatch 49900, batch loss 0.952265, batch nll 0.432996, batch error rate 16.000000%\n",
      "At minibatch 50000, batch loss 0.910071, batch nll 0.390854, batch error rate 12.000000%\n",
      "At minibatch 50100, batch loss 0.830051, batch nll 0.309282, batch error rate 8.000000%\n",
      "At minibatch 50200, batch loss 1.016555, batch nll 0.495330, batch error rate 16.000000%\n",
      "At minibatch 50300, batch loss 0.906065, batch nll 0.383729, batch error rate 8.000000%\n",
      "At minibatch 50400, batch loss 1.401103, batch nll 0.878156, batch error rate 28.000000%\n",
      "At minibatch 50500, batch loss 0.761689, batch nll 0.238893, batch error rate 8.000000%\n",
      "At minibatch 50600, batch loss 0.830738, batch nll 0.308142, batch error rate 8.000000%\n",
      "At minibatch 50700, batch loss 1.064619, batch nll 0.542935, batch error rate 20.000000%\n",
      "At minibatch 50800, batch loss 0.907966, batch nll 0.386925, batch error rate 4.000000%\n",
      "At minibatch 50900, batch loss 0.909314, batch nll 0.389041, batch error rate 8.000000%\n",
      "At minibatch 51000, batch loss 0.924478, batch nll 0.404083, batch error rate 8.000000%\n",
      "At minibatch 51100, batch loss 0.868149, batch nll 0.349201, batch error rate 8.000000%\n",
      "At minibatch 51200, batch loss 0.839740, batch nll 0.321700, batch error rate 12.000000%\n",
      "After epoch 32: valid_err_rate: 24.060000% currently going to do 49 epochs\n",
      "After epoch 32: averaged train_err_rate: 16.055000% averaged train nll: 0.479919 averaged train loss: 1.000040\n",
      "At minibatch 51300, batch loss 0.781056, batch nll 0.261731, batch error rate 12.000000%\n",
      "At minibatch 51400, batch loss 0.857742, batch nll 0.338134, batch error rate 8.000000%\n",
      "At minibatch 51500, batch loss 0.803390, batch nll 0.282191, batch error rate 12.000000%\n",
      "At minibatch 51600, batch loss 1.018754, batch nll 0.497555, batch error rate 24.000000%\n",
      "At minibatch 51700, batch loss 0.782916, batch nll 0.260339, batch error rate 4.000000%\n",
      "At minibatch 51800, batch loss 0.940894, batch nll 0.417901, batch error rate 4.000000%\n",
      "At minibatch 51900, batch loss 0.846437, batch nll 0.323061, batch error rate 12.000000%\n",
      "At minibatch 52000, batch loss 0.740414, batch nll 0.215795, batch error rate 4.000000%\n",
      "At minibatch 52100, batch loss 0.812069, batch nll 0.287925, batch error rate 8.000000%\n",
      "At minibatch 52200, batch loss 0.911125, batch nll 0.386519, batch error rate 12.000000%\n",
      "At minibatch 52300, batch loss 1.188096, batch nll 0.663323, batch error rate 28.000000%\n",
      "At minibatch 52400, batch loss 1.100351, batch nll 0.575768, batch error rate 24.000000%\n",
      "At minibatch 52500, batch loss 0.862932, batch nll 0.338073, batch error rate 4.000000%\n",
      "At minibatch 52600, batch loss 0.976731, batch nll 0.452664, batch error rate 16.000000%\n",
      "At minibatch 52700, batch loss 1.104135, batch nll 0.580849, batch error rate 24.000000%\n",
      "At minibatch 52800, batch loss 1.020143, batch nll 0.498832, batch error rate 24.000000%\n",
      "After epoch 33: valid_err_rate: 24.430000% currently going to do 49 epochs\n",
      "After epoch 33: averaged train_err_rate: 15.385000% averaged train nll: 0.462518 averaged train loss: 0.985326\n",
      "At minibatch 52900, batch loss 1.048509, batch nll 0.526134, batch error rate 16.000000%\n",
      "At minibatch 53000, batch loss 0.922056, batch nll 0.399056, batch error rate 12.000000%\n",
      "At minibatch 53100, batch loss 0.679545, batch nll 0.155755, batch error rate 4.000000%\n",
      "At minibatch 53200, batch loss 1.011534, batch nll 0.486261, batch error rate 8.000000%\n",
      "At minibatch 53300, batch loss 1.155261, batch nll 0.629160, batch error rate 24.000000%\n",
      "At minibatch 53400, batch loss 1.063340, batch nll 0.537195, batch error rate 12.000000%\n",
      "At minibatch 53500, batch loss 1.119755, batch nll 0.593005, batch error rate 20.000000%\n",
      "At minibatch 53600, batch loss 0.865429, batch nll 0.337882, batch error rate 16.000000%\n",
      "At minibatch 53700, batch loss 0.931951, batch nll 0.404949, batch error rate 16.000000%\n",
      "At minibatch 53800, batch loss 1.133962, batch nll 0.606024, batch error rate 12.000000%\n",
      "At minibatch 53900, batch loss 0.950329, batch nll 0.422264, batch error rate 16.000000%\n",
      "At minibatch 54000, batch loss 0.879668, batch nll 0.351083, batch error rate 12.000000%\n",
      "At minibatch 54100, batch loss 1.008510, batch nll 0.480935, batch error rate 20.000000%\n",
      "At minibatch 54200, batch loss 1.159592, batch nll 0.632826, batch error rate 28.000000%\n",
      "At minibatch 54300, batch loss 1.254242, batch nll 0.728472, batch error rate 20.000000%\n",
      "At minibatch 54400, batch loss 1.234996, batch nll 0.710540, batch error rate 32.000000%\n",
      "After epoch 34: valid_err_rate: 25.430000% currently going to do 49 epochs\n",
      "After epoch 34: averaged train_err_rate: 14.985000% averaged train nll: 0.455471 averaged train loss: 0.981471\n",
      "At minibatch 54500, batch loss 1.029093, batch nll 0.503511, batch error rate 24.000000%\n",
      "At minibatch 54600, batch loss 0.918831, batch nll 0.391371, batch error rate 16.000000%\n",
      "At minibatch 54700, batch loss 0.706404, batch nll 0.177634, batch error rate 0.000000%\n",
      "At minibatch 54800, batch loss 1.105396, batch nll 0.576806, batch error rate 24.000000%\n",
      "At minibatch 54900, batch loss 1.183480, batch nll 0.654123, batch error rate 24.000000%\n",
      "At minibatch 55000, batch loss 1.064779, batch nll 0.534725, batch error rate 24.000000%\n",
      "At minibatch 55100, batch loss 1.018108, batch nll 0.487712, batch error rate 16.000000%\n",
      "At minibatch 55200, batch loss 1.130925, batch nll 0.600805, batch error rate 24.000000%\n",
      "At minibatch 55300, batch loss 0.983868, batch nll 0.453485, batch error rate 20.000000%\n",
      "At minibatch 55400, batch loss 0.801918, batch nll 0.271428, batch error rate 8.000000%\n",
      "At minibatch 55500, batch loss 1.015741, batch nll 0.485067, batch error rate 16.000000%\n",
      "At minibatch 55600, batch loss 0.957773, batch nll 0.428185, batch error rate 12.000000%\n",
      "At minibatch 55700, batch loss 1.173985, batch nll 0.645306, batch error rate 24.000000%\n",
      "At minibatch 55800, batch loss 0.908399, batch nll 0.380372, batch error rate 8.000000%\n",
      "At minibatch 55900, batch loss 0.936774, batch nll 0.409322, batch error rate 12.000000%\n",
      "At minibatch 56000, batch loss 1.322575, batch nll 0.795578, batch error rate 20.000000%\n",
      "After epoch 35: valid_err_rate: 23.770000% currently going to do 53 epochs\n",
      "After epoch 35: averaged train_err_rate: 14.512500% averaged train nll: 0.443951 averaged train loss: 0.972720\n",
      "At minibatch 56100, batch loss 0.786785, batch nll 0.258827, batch error rate 4.000000%\n",
      "At minibatch 56200, batch loss 0.979983, batch nll 0.450706, batch error rate 20.000000%\n",
      "At minibatch 56300, batch loss 0.900526, batch nll 0.370333, batch error rate 8.000000%\n",
      "At minibatch 56400, batch loss 1.030352, batch nll 0.499439, batch error rate 12.000000%\n",
      "At minibatch 56500, batch loss 0.768774, batch nll 0.236590, batch error rate 8.000000%\n",
      "At minibatch 56600, batch loss 0.901674, batch nll 0.370031, batch error rate 16.000000%\n",
      "At minibatch 56700, batch loss 1.148593, batch nll 0.616035, batch error rate 28.000000%\n",
      "At minibatch 56800, batch loss 1.024060, batch nll 0.492049, batch error rate 24.000000%\n",
      "At minibatch 56900, batch loss 0.906475, batch nll 0.375032, batch error rate 16.000000%\n",
      "At minibatch 57000, batch loss 1.180844, batch nll 0.648941, batch error rate 16.000000%\n",
      "At minibatch 57100, batch loss 1.039855, batch nll 0.508587, batch error rate 20.000000%\n",
      "At minibatch 57200, batch loss 1.064350, batch nll 0.532287, batch error rate 20.000000%\n",
      "At minibatch 57300, batch loss 1.353072, batch nll 0.821217, batch error rate 32.000000%\n",
      "At minibatch 57400, batch loss 0.852656, batch nll 0.320637, batch error rate 16.000000%\n",
      "At minibatch 57500, batch loss 0.840979, batch nll 0.309771, batch error rate 8.000000%\n",
      "At minibatch 57600, batch loss 0.943746, batch nll 0.413902, batch error rate 12.000000%\n",
      "After epoch 36: valid_err_rate: 25.220000% currently going to do 53 epochs\n",
      "After epoch 36: averaged train_err_rate: 14.082500% averaged train nll: 0.426860 averaged train loss: 0.957888\n",
      "At minibatch 57700, batch loss 1.341349, batch nll 0.810445, batch error rate 24.000000%\n",
      "At minibatch 57800, batch loss 0.881400, batch nll 0.349159, batch error rate 12.000000%\n",
      "At minibatch 57900, batch loss 0.886037, batch nll 0.353578, batch error rate 20.000000%\n",
      "At minibatch 58000, batch loss 1.042168, batch nll 0.508864, batch error rate 20.000000%\n",
      "At minibatch 58100, batch loss 1.341082, batch nll 0.807251, batch error rate 16.000000%\n",
      "At minibatch 58200, batch loss 0.878696, batch nll 0.343962, batch error rate 12.000000%\n",
      "At minibatch 58300, batch loss 0.906140, batch nll 0.372151, batch error rate 12.000000%\n",
      "At minibatch 58400, batch loss 0.927852, batch nll 0.393299, batch error rate 8.000000%\n",
      "At minibatch 58500, batch loss 1.001432, batch nll 0.467320, batch error rate 24.000000%\n",
      "At minibatch 58600, batch loss 0.650717, batch nll 0.116627, batch error rate 0.000000%\n",
      "At minibatch 58700, batch loss 1.126348, batch nll 0.591443, batch error rate 12.000000%\n",
      "At minibatch 58800, batch loss 0.927134, batch nll 0.391950, batch error rate 16.000000%\n",
      "At minibatch 58900, batch loss 0.804591, batch nll 0.270196, batch error rate 8.000000%\n",
      "At minibatch 59000, batch loss 1.007571, batch nll 0.473531, batch error rate 20.000000%\n",
      "At minibatch 59100, batch loss 0.917589, batch nll 0.383331, batch error rate 12.000000%\n",
      "At minibatch 59200, batch loss 1.026482, batch nll 0.492695, batch error rate 20.000000%\n",
      "After epoch 37: valid_err_rate: 24.220000% currently going to do 53 epochs\n",
      "After epoch 37: averaged train_err_rate: 13.667500% averaged train nll: 0.419855 averaged train loss: 0.953550\n",
      "At minibatch 59300, batch loss 1.108440, batch nll 0.573869, batch error rate 24.000000%\n",
      "At minibatch 59400, batch loss 0.987705, batch nll 0.451669, batch error rate 12.000000%\n",
      "At minibatch 59500, batch loss 0.871641, batch nll 0.335860, batch error rate 12.000000%\n",
      "At minibatch 59600, batch loss 0.845226, batch nll 0.308932, batch error rate 8.000000%\n",
      "At minibatch 59700, batch loss 1.126092, batch nll 0.588477, batch error rate 12.000000%\n",
      "At minibatch 59800, batch loss 0.887706, batch nll 0.349824, batch error rate 4.000000%\n",
      "At minibatch 59900, batch loss 0.708901, batch nll 0.171112, batch error rate 4.000000%\n",
      "At minibatch 60000, batch loss 0.732824, batch nll 0.194499, batch error rate 4.000000%\n",
      "At minibatch 60100, batch loss 1.011794, batch nll 0.473273, batch error rate 16.000000%\n",
      "At minibatch 60200, batch loss 1.035638, batch nll 0.497381, batch error rate 12.000000%\n",
      "At minibatch 60300, batch loss 0.794345, batch nll 0.257625, batch error rate 12.000000%\n",
      "At minibatch 60400, batch loss 0.947367, batch nll 0.411385, batch error rate 12.000000%\n",
      "At minibatch 60500, batch loss 0.887897, batch nll 0.352293, batch error rate 12.000000%\n",
      "At minibatch 60600, batch loss 0.996741, batch nll 0.461563, batch error rate 20.000000%\n",
      "At minibatch 60700, batch loss 1.036605, batch nll 0.501594, batch error rate 20.000000%\n",
      "At minibatch 60800, batch loss 0.787331, batch nll 0.251874, batch error rate 4.000000%\n",
      "After epoch 38: valid_err_rate: 25.780000% currently going to do 53 epochs\n",
      "After epoch 38: averaged train_err_rate: 13.207500% averaged train nll: 0.409443 averaged train loss: 0.945998\n",
      "At minibatch 60900, batch loss 1.112508, batch nll 0.576677, batch error rate 20.000000%\n",
      "At minibatch 61000, batch loss 0.753698, batch nll 0.217240, batch error rate 4.000000%\n",
      "At minibatch 61100, batch loss 0.922606, batch nll 0.385368, batch error rate 12.000000%\n",
      "At minibatch 61200, batch loss 0.865562, batch nll 0.328098, batch error rate 8.000000%\n",
      "At minibatch 61300, batch loss 0.752949, batch nll 0.214487, batch error rate 8.000000%\n",
      "At minibatch 61400, batch loss 0.755723, batch nll 0.215927, batch error rate 4.000000%\n",
      "At minibatch 61500, batch loss 0.836042, batch nll 0.296439, batch error rate 8.000000%\n",
      "At minibatch 61600, batch loss 1.052649, batch nll 0.512342, batch error rate 12.000000%\n",
      "At minibatch 61700, batch loss 0.883107, batch nll 0.342768, batch error rate 8.000000%\n",
      "At minibatch 61800, batch loss 0.738659, batch nll 0.198272, batch error rate 4.000000%\n",
      "At minibatch 61900, batch loss 0.960396, batch nll 0.420387, batch error rate 12.000000%\n",
      "At minibatch 62000, batch loss 0.837289, batch nll 0.298501, batch error rate 4.000000%\n",
      "At minibatch 62100, batch loss 1.080589, batch nll 0.542149, batch error rate 28.000000%\n",
      "At minibatch 62200, batch loss 0.727928, batch nll 0.189724, batch error rate 8.000000%\n",
      "At minibatch 62300, batch loss 0.809827, batch nll 0.272383, batch error rate 4.000000%\n",
      "At minibatch 62400, batch loss 0.809583, batch nll 0.273044, batch error rate 4.000000%\n",
      "After epoch 39: valid_err_rate: 24.340000% currently going to do 53 epochs\n",
      "After epoch 39: averaged train_err_rate: 12.755000% averaged train nll: 0.397409 averaged train loss: 0.935848\n",
      "At minibatch 62500, batch loss 0.892076, batch nll 0.354476, batch error rate 8.000000%\n",
      "At minibatch 62600, batch loss 0.875987, batch nll 0.338807, batch error rate 8.000000%\n",
      "At minibatch 62700, batch loss 0.764541, batch nll 0.226951, batch error rate 8.000000%\n",
      "At minibatch 62800, batch loss 0.984823, batch nll 0.446902, batch error rate 8.000000%\n",
      "At minibatch 62900, batch loss 1.175235, batch nll 0.635580, batch error rate 24.000000%\n",
      "At minibatch 63000, batch loss 0.865519, batch nll 0.325368, batch error rate 12.000000%\n",
      "At minibatch 63100, batch loss 0.892917, batch nll 0.353357, batch error rate 12.000000%\n",
      "At minibatch 63200, batch loss 0.981775, batch nll 0.441772, batch error rate 12.000000%\n",
      "At minibatch 63300, batch loss 0.825699, batch nll 0.285252, batch error rate 8.000000%\n",
      "At minibatch 63400, batch loss 0.904902, batch nll 0.364336, batch error rate 12.000000%\n",
      "At minibatch 63500, batch loss 0.818837, batch nll 0.277493, batch error rate 8.000000%\n",
      "At minibatch 63600, batch loss 0.844074, batch nll 0.303087, batch error rate 12.000000%\n",
      "At minibatch 63700, batch loss 1.044686, batch nll 0.504104, batch error rate 16.000000%\n",
      "At minibatch 63800, batch loss 1.000955, batch nll 0.459613, batch error rate 16.000000%\n",
      "At minibatch 63900, batch loss 0.938569, batch nll 0.397522, batch error rate 8.000000%\n",
      "At minibatch 64000, batch loss 0.974405, batch nll 0.433840, batch error rate 8.000000%\n",
      "After epoch 40: valid_err_rate: 25.180000% currently going to do 53 epochs\n",
      "After epoch 40: averaged train_err_rate: 12.480000% averaged train nll: 0.389664 averaged train loss: 0.929264\n",
      "At minibatch 64100, batch loss 0.794283, batch nll 0.253564, batch error rate 4.000000%\n",
      "At minibatch 64200, batch loss 0.932510, batch nll 0.391447, batch error rate 12.000000%\n",
      "At minibatch 64300, batch loss 0.705487, batch nll 0.163922, batch error rate 4.000000%\n",
      "At minibatch 64400, batch loss 0.816668, batch nll 0.274592, batch error rate 8.000000%\n",
      "At minibatch 64500, batch loss 0.918323, batch nll 0.375581, batch error rate 16.000000%\n",
      "At minibatch 64600, batch loss 1.135664, batch nll 0.593044, batch error rate 16.000000%\n",
      "At minibatch 64700, batch loss 0.724120, batch nll 0.181681, batch error rate 4.000000%\n",
      "At minibatch 64800, batch loss 0.756002, batch nll 0.212735, batch error rate 0.000000%\n",
      "At minibatch 64900, batch loss 0.778247, batch nll 0.235174, batch error rate 4.000000%\n",
      "At minibatch 65000, batch loss 1.295333, batch nll 0.752150, batch error rate 28.000000%\n",
      "At minibatch 65100, batch loss 1.005267, batch nll 0.461686, batch error rate 4.000000%\n",
      "At minibatch 65200, batch loss 0.901936, batch nll 0.358390, batch error rate 12.000000%\n",
      "At minibatch 65300, batch loss 1.199483, batch nll 0.656025, batch error rate 24.000000%\n",
      "At minibatch 65400, batch loss 1.344466, batch nll 0.801260, batch error rate 24.000000%\n",
      "At minibatch 65500, batch loss 0.954588, batch nll 0.411632, batch error rate 12.000000%\n",
      "At minibatch 65600, batch loss 0.949508, batch nll 0.407594, batch error rate 16.000000%\n",
      "After epoch 41: valid_err_rate: 24.620000% currently going to do 53 epochs\n",
      "After epoch 41: averaged train_err_rate: 11.940000% averaged train nll: 0.380401 averaged train loss: 0.922866\n",
      "At minibatch 65700, batch loss 0.785707, batch nll 0.243055, batch error rate 4.000000%\n",
      "At minibatch 65800, batch loss 0.811677, batch nll 0.268540, batch error rate 8.000000%\n",
      "At minibatch 65900, batch loss 0.820584, batch nll 0.277772, batch error rate 4.000000%\n",
      "At minibatch 66000, batch loss 0.824242, batch nll 0.280648, batch error rate 16.000000%\n",
      "At minibatch 66100, batch loss 0.724957, batch nll 0.180348, batch error rate 4.000000%\n",
      "At minibatch 66200, batch loss 0.937765, batch nll 0.393282, batch error rate 8.000000%\n",
      "At minibatch 66300, batch loss 0.831318, batch nll 0.286740, batch error rate 8.000000%\n",
      "At minibatch 66400, batch loss 0.884197, batch nll 0.339770, batch error rate 8.000000%\n",
      "At minibatch 66500, batch loss 0.820069, batch nll 0.274782, batch error rate 4.000000%\n",
      "At minibatch 66600, batch loss 0.789773, batch nll 0.243798, batch error rate 4.000000%\n",
      "At minibatch 66700, batch loss 0.684784, batch nll 0.138012, batch error rate 0.000000%\n",
      "At minibatch 66800, batch loss 0.710189, batch nll 0.163884, batch error rate 8.000000%\n",
      "At minibatch 66900, batch loss 0.993363, batch nll 0.447585, batch error rate 16.000000%\n",
      "At minibatch 67000, batch loss 0.873185, batch nll 0.328652, batch error rate 8.000000%\n",
      "At minibatch 67100, batch loss 1.039831, batch nll 0.495385, batch error rate 12.000000%\n",
      "At minibatch 67200, batch loss 0.830854, batch nll 0.286136, batch error rate 8.000000%\n",
      "After epoch 42: valid_err_rate: 24.030000% currently going to do 53 epochs\n",
      "After epoch 42: averaged train_err_rate: 11.465000% averaged train nll: 0.370733 averaged train loss: 0.915203\n",
      "At minibatch 67300, batch loss 0.863269, batch nll 0.317625, batch error rate 8.000000%\n",
      "At minibatch 67400, batch loss 0.726422, batch nll 0.180557, batch error rate 4.000000%\n",
      "At minibatch 67500, batch loss 0.819367, batch nll 0.272722, batch error rate 12.000000%\n",
      "At minibatch 67600, batch loss 0.921764, batch nll 0.375338, batch error rate 12.000000%\n",
      "At minibatch 67700, batch loss 1.007709, batch nll 0.461110, batch error rate 12.000000%\n",
      "At minibatch 67800, batch loss 1.148969, batch nll 0.602611, batch error rate 24.000000%\n",
      "At minibatch 67900, batch loss 1.098235, batch nll 0.551406, batch error rate 16.000000%\n",
      "At minibatch 68000, batch loss 0.957103, batch nll 0.409784, batch error rate 20.000000%\n",
      "At minibatch 68100, batch loss 0.882993, batch nll 0.335353, batch error rate 12.000000%\n",
      "At minibatch 68200, batch loss 0.926194, batch nll 0.378484, batch error rate 12.000000%\n",
      "At minibatch 68300, batch loss 0.988440, batch nll 0.441089, batch error rate 16.000000%\n",
      "At minibatch 68400, batch loss 0.927438, batch nll 0.380337, batch error rate 12.000000%\n",
      "At minibatch 68500, batch loss 0.967207, batch nll 0.420741, batch error rate 16.000000%\n",
      "At minibatch 68600, batch loss 0.671039, batch nll 0.124627, batch error rate 0.000000%\n",
      "At minibatch 68700, batch loss 1.035931, batch nll 0.489277, batch error rate 20.000000%\n",
      "At minibatch 68800, batch loss 0.944071, batch nll 0.397635, batch error rate 12.000000%\n",
      "After epoch 43: valid_err_rate: 23.710000% currently going to do 65 epochs\n",
      "After epoch 43: averaged train_err_rate: 11.405000% averaged train nll: 0.364534 averaged train loss: 0.911216\n",
      "At minibatch 68900, batch loss 0.843056, batch nll 0.296259, batch error rate 8.000000%\n",
      "At minibatch 69000, batch loss 0.663764, batch nll 0.117417, batch error rate 0.000000%\n",
      "At minibatch 69100, batch loss 0.955995, batch nll 0.409253, batch error rate 12.000000%\n",
      "At minibatch 69200, batch loss 0.720718, batch nll 0.174632, batch error rate 0.000000%\n",
      "At minibatch 69300, batch loss 0.858481, batch nll 0.311952, batch error rate 8.000000%\n",
      "At minibatch 69400, batch loss 1.045626, batch nll 0.498871, batch error rate 24.000000%\n",
      "At minibatch 69500, batch loss 1.090595, batch nll 0.543330, batch error rate 16.000000%\n",
      "At minibatch 69600, batch loss 0.906940, batch nll 0.360390, batch error rate 16.000000%\n",
      "At minibatch 69700, batch loss 0.908066, batch nll 0.361055, batch error rate 20.000000%\n",
      "At minibatch 69800, batch loss 1.247461, batch nll 0.699733, batch error rate 20.000000%\n",
      "At minibatch 69900, batch loss 0.789110, batch nll 0.241102, batch error rate 4.000000%\n",
      "At minibatch 70000, batch loss 0.906947, batch nll 0.359256, batch error rate 8.000000%\n",
      "At minibatch 70100, batch loss 0.943388, batch nll 0.396240, batch error rate 4.000000%\n",
      "At minibatch 70200, batch loss 0.769348, batch nll 0.222601, batch error rate 4.000000%\n",
      "At minibatch 70300, batch loss 1.028566, batch nll 0.481758, batch error rate 12.000000%\n",
      "At minibatch 70400, batch loss 1.092847, batch nll 0.546080, batch error rate 16.000000%\n",
      "After epoch 44: valid_err_rate: 25.670000% currently going to do 65 epochs\n",
      "After epoch 44: averaged train_err_rate: 10.827500% averaged train nll: 0.350466 averaged train loss: 0.897452\n",
      "At minibatch 70500, batch loss 0.762893, batch nll 0.215764, batch error rate 0.000000%\n",
      "At minibatch 70600, batch loss 0.871759, batch nll 0.324441, batch error rate 12.000000%\n",
      "At minibatch 70700, batch loss 0.768547, batch nll 0.221625, batch error rate 4.000000%\n",
      "At minibatch 70800, batch loss 0.801347, batch nll 0.254249, batch error rate 4.000000%\n",
      "At minibatch 70900, batch loss 1.020254, batch nll 0.471749, batch error rate 12.000000%\n",
      "At minibatch 71000, batch loss 1.002059, batch nll 0.453144, batch error rate 20.000000%\n",
      "At minibatch 71100, batch loss 0.806750, batch nll 0.258080, batch error rate 12.000000%\n",
      "At minibatch 71200, batch loss 0.868050, batch nll 0.318649, batch error rate 8.000000%\n",
      "At minibatch 71300, batch loss 1.087584, batch nll 0.537813, batch error rate 16.000000%\n",
      "At minibatch 71400, batch loss 0.916149, batch nll 0.366336, batch error rate 20.000000%\n",
      "At minibatch 71500, batch loss 0.854594, batch nll 0.304886, batch error rate 16.000000%\n",
      "At minibatch 71600, batch loss 0.756221, batch nll 0.206612, batch error rate 12.000000%\n",
      "At minibatch 71700, batch loss 0.723628, batch nll 0.173507, batch error rate 0.000000%\n",
      "At minibatch 71800, batch loss 0.864564, batch nll 0.314568, batch error rate 8.000000%\n",
      "At minibatch 71900, batch loss 1.046533, batch nll 0.496677, batch error rate 16.000000%\n",
      "At minibatch 72000, batch loss 0.942604, batch nll 0.392814, batch error rate 12.000000%\n",
      "After epoch 45: valid_err_rate: 24.630000% currently going to do 65 epochs\n",
      "After epoch 45: averaged train_err_rate: 10.795000% averaged train nll: 0.347248 averaged train loss: 0.896076\n",
      "At minibatch 72100, batch loss 0.981510, batch nll 0.431674, batch error rate 12.000000%\n",
      "At minibatch 72200, batch loss 0.722228, batch nll 0.172516, batch error rate 0.000000%\n",
      "At minibatch 72300, batch loss 0.761652, batch nll 0.211182, batch error rate 8.000000%\n",
      "At minibatch 72400, batch loss 0.911276, batch nll 0.360744, batch error rate 12.000000%\n",
      "At minibatch 72500, batch loss 0.835862, batch nll 0.285463, batch error rate 8.000000%\n",
      "At minibatch 72600, batch loss 0.911974, batch nll 0.360312, batch error rate 16.000000%\n",
      "At minibatch 72700, batch loss 0.878753, batch nll 0.326993, batch error rate 8.000000%\n",
      "At minibatch 72800, batch loss 0.852452, batch nll 0.300211, batch error rate 8.000000%\n",
      "At minibatch 72900, batch loss 0.772138, batch nll 0.219718, batch error rate 4.000000%\n",
      "At minibatch 73000, batch loss 1.202588, batch nll 0.650207, batch error rate 20.000000%\n",
      "At minibatch 73100, batch loss 1.019683, batch nll 0.468272, batch error rate 16.000000%\n",
      "At minibatch 73200, batch loss 1.061059, batch nll 0.509096, batch error rate 12.000000%\n",
      "At minibatch 73300, batch loss 0.890517, batch nll 0.338927, batch error rate 8.000000%\n",
      "At minibatch 73400, batch loss 1.260886, batch nll 0.710243, batch error rate 28.000000%\n",
      "At minibatch 73500, batch loss 1.196607, batch nll 0.646240, batch error rate 20.000000%\n",
      "At minibatch 73600, batch loss 0.932035, batch nll 0.381409, batch error rate 16.000000%\n",
      "After epoch 46: valid_err_rate: 25.400000% currently going to do 65 epochs\n",
      "After epoch 46: averaged train_err_rate: 10.405000% averaged train nll: 0.339955 averaged train loss: 0.891093\n",
      "At minibatch 73700, batch loss 0.775680, batch nll 0.224973, batch error rate 4.000000%\n",
      "At minibatch 73800, batch loss 0.695597, batch nll 0.145082, batch error rate 0.000000%\n",
      "At minibatch 73900, batch loss 0.838187, batch nll 0.287472, batch error rate 8.000000%\n",
      "At minibatch 74000, batch loss 0.963276, batch nll 0.412982, batch error rate 16.000000%\n",
      "At minibatch 74100, batch loss 0.843887, batch nll 0.293233, batch error rate 12.000000%\n",
      "At minibatch 74200, batch loss 0.670436, batch nll 0.119526, batch error rate 4.000000%\n",
      "At minibatch 74300, batch loss 0.970633, batch nll 0.419548, batch error rate 16.000000%\n",
      "At minibatch 74400, batch loss 0.874682, batch nll 0.323424, batch error rate 12.000000%\n",
      "At minibatch 74500, batch loss 0.901854, batch nll 0.350287, batch error rate 8.000000%\n",
      "At minibatch 74600, batch loss 0.841295, batch nll 0.289571, batch error rate 8.000000%\n",
      "At minibatch 74700, batch loss 0.765863, batch nll 0.214026, batch error rate 4.000000%\n",
      "At minibatch 74800, batch loss 0.790915, batch nll 0.239254, batch error rate 12.000000%\n",
      "At minibatch 74900, batch loss 0.910833, batch nll 0.358944, batch error rate 12.000000%\n",
      "At minibatch 75000, batch loss 0.867909, batch nll 0.315509, batch error rate 8.000000%\n",
      "At minibatch 75100, batch loss 0.838709, batch nll 0.286300, batch error rate 8.000000%\n",
      "At minibatch 75200, batch loss 0.954408, batch nll 0.402125, batch error rate 12.000000%\n",
      "After epoch 47: valid_err_rate: 25.110000% currently going to do 65 epochs\n",
      "After epoch 47: averaged train_err_rate: 10.122500% averaged train nll: 0.333210 averaged train loss: 0.884538\n",
      "At minibatch 75300, batch loss 0.934007, batch nll 0.381332, batch error rate 8.000000%\n",
      "At minibatch 75400, batch loss 0.916122, batch nll 0.363317, batch error rate 12.000000%\n",
      "At minibatch 75500, batch loss 0.850588, batch nll 0.298085, batch error rate 16.000000%\n",
      "At minibatch 75600, batch loss 0.993186, batch nll 0.439310, batch error rate 20.000000%\n",
      "At minibatch 75700, batch loss 0.893054, batch nll 0.338866, batch error rate 12.000000%\n",
      "At minibatch 75800, batch loss 0.929665, batch nll 0.375987, batch error rate 12.000000%\n",
      "At minibatch 75900, batch loss 0.815765, batch nll 0.262102, batch error rate 12.000000%\n",
      "At minibatch 76000, batch loss 1.028538, batch nll 0.473936, batch error rate 20.000000%\n",
      "At minibatch 76100, batch loss 0.890053, batch nll 0.335635, batch error rate 4.000000%\n",
      "At minibatch 76200, batch loss 0.958706, batch nll 0.404700, batch error rate 20.000000%\n",
      "At minibatch 76300, batch loss 0.901568, batch nll 0.346973, batch error rate 8.000000%\n",
      "At minibatch 76400, batch loss 0.677973, batch nll 0.123331, batch error rate 0.000000%\n",
      "At minibatch 76500, batch loss 0.819396, batch nll 0.265679, batch error rate 4.000000%\n",
      "At minibatch 76600, batch loss 0.795525, batch nll 0.242270, batch error rate 4.000000%\n",
      "At minibatch 76700, batch loss 1.058219, batch nll 0.504970, batch error rate 24.000000%\n",
      "At minibatch 76800, batch loss 0.824450, batch nll 0.272559, batch error rate 4.000000%\n",
      "After epoch 48: valid_err_rate: 24.250000% currently going to do 65 epochs\n",
      "After epoch 48: averaged train_err_rate: 9.902500% averaged train nll: 0.326453 averaged train loss: 0.880041\n",
      "At minibatch 76900, batch loss 0.781226, batch nll 0.228276, batch error rate 4.000000%\n",
      "At minibatch 77000, batch loss 0.988530, batch nll 0.435498, batch error rate 16.000000%\n",
      "At minibatch 77100, batch loss 0.714588, batch nll 0.161534, batch error rate 4.000000%\n",
      "At minibatch 77200, batch loss 0.695463, batch nll 0.142223, batch error rate 4.000000%\n",
      "At minibatch 77300, batch loss 0.982164, batch nll 0.428997, batch error rate 16.000000%\n",
      "At minibatch 77400, batch loss 0.765828, batch nll 0.212813, batch error rate 4.000000%\n",
      "At minibatch 77500, batch loss 0.925361, batch nll 0.372151, batch error rate 12.000000%\n",
      "At minibatch 77600, batch loss 0.846205, batch nll 0.292209, batch error rate 4.000000%\n",
      "At minibatch 77700, batch loss 1.291444, batch nll 0.737337, batch error rate 32.000000%\n",
      "At minibatch 77800, batch loss 0.910177, batch nll 0.356005, batch error rate 16.000000%\n",
      "At minibatch 77900, batch loss 0.909952, batch nll 0.356025, batch error rate 12.000000%\n",
      "At minibatch 78000, batch loss 0.873003, batch nll 0.319634, batch error rate 8.000000%\n",
      "At minibatch 78100, batch loss 0.795848, batch nll 0.241644, batch error rate 8.000000%\n",
      "At minibatch 78200, batch loss 0.727534, batch nll 0.174452, batch error rate 0.000000%\n",
      "At minibatch 78300, batch loss 0.803663, batch nll 0.250517, batch error rate 4.000000%\n",
      "At minibatch 78400, batch loss 0.758652, batch nll 0.205949, batch error rate 4.000000%\n",
      "After epoch 49: valid_err_rate: 23.860000% currently going to do 65 epochs\n",
      "After epoch 49: averaged train_err_rate: 9.672500% averaged train nll: 0.317568 averaged train loss: 0.870991\n",
      "At minibatch 78500, batch loss 0.706344, batch nll 0.153522, batch error rate 0.000000%\n",
      "At minibatch 78600, batch loss 0.932082, batch nll 0.379159, batch error rate 12.000000%\n",
      "At minibatch 78700, batch loss 0.783269, batch nll 0.230658, batch error rate 4.000000%\n",
      "At minibatch 78800, batch loss 0.806898, batch nll 0.253848, batch error rate 8.000000%\n",
      "At minibatch 78900, batch loss 0.881492, batch nll 0.327797, batch error rate 8.000000%\n",
      "At minibatch 79000, batch loss 0.918942, batch nll 0.365288, batch error rate 4.000000%\n",
      "At minibatch 79100, batch loss 1.007307, batch nll 0.453442, batch error rate 12.000000%\n",
      "At minibatch 79200, batch loss 0.745697, batch nll 0.191794, batch error rate 8.000000%\n",
      "At minibatch 79300, batch loss 0.807522, batch nll 0.253905, batch error rate 8.000000%\n",
      "At minibatch 79400, batch loss 0.741403, batch nll 0.187712, batch error rate 0.000000%\n",
      "At minibatch 79500, batch loss 0.737364, batch nll 0.183190, batch error rate 8.000000%\n",
      "At minibatch 79600, batch loss 0.773259, batch nll 0.218885, batch error rate 0.000000%\n",
      "At minibatch 79700, batch loss 0.848004, batch nll 0.293515, batch error rate 8.000000%\n",
      "At minibatch 79800, batch loss 0.882235, batch nll 0.327779, batch error rate 8.000000%\n",
      "At minibatch 79900, batch loss 0.775831, batch nll 0.222010, batch error rate 4.000000%\n",
      "At minibatch 80000, batch loss 0.774934, batch nll 0.220848, batch error rate 0.000000%\n",
      "After epoch 50: valid_err_rate: 24.320000% currently going to do 65 epochs\n",
      "After epoch 50: averaged train_err_rate: 9.172500% averaged train nll: 0.310898 averaged train loss: 0.864552\n",
      "At minibatch 80100, batch loss 0.840626, batch nll 0.286760, batch error rate 12.000000%\n",
      "At minibatch 80200, batch loss 1.133764, batch nll 0.580748, batch error rate 28.000000%\n",
      "At minibatch 80300, batch loss 0.858421, batch nll 0.305458, batch error rate 8.000000%\n",
      "At minibatch 80400, batch loss 0.893521, batch nll 0.340056, batch error rate 16.000000%\n",
      "At minibatch 80500, batch loss 0.894759, batch nll 0.341474, batch error rate 8.000000%\n",
      "At minibatch 80600, batch loss 0.805120, batch nll 0.252162, batch error rate 4.000000%\n",
      "At minibatch 80700, batch loss 0.736330, batch nll 0.183253, batch error rate 4.000000%\n",
      "At minibatch 80800, batch loss 0.972497, batch nll 0.419212, batch error rate 8.000000%\n",
      "At minibatch 80900, batch loss 0.876613, batch nll 0.323002, batch error rate 8.000000%\n",
      "At minibatch 81000, batch loss 0.812559, batch nll 0.258786, batch error rate 8.000000%\n",
      "At minibatch 81100, batch loss 0.861387, batch nll 0.307308, batch error rate 16.000000%\n",
      "At minibatch 81200, batch loss 1.060346, batch nll 0.506505, batch error rate 24.000000%\n",
      "At minibatch 81300, batch loss 1.152989, batch nll 0.598417, batch error rate 24.000000%\n",
      "At minibatch 81400, batch loss 0.772545, batch nll 0.217784, batch error rate 4.000000%\n",
      "At minibatch 81500, batch loss 0.987087, batch nll 0.432271, batch error rate 16.000000%\n",
      "At minibatch 81600, batch loss 1.065415, batch nll 0.510701, batch error rate 20.000000%\n",
      "After epoch 51: valid_err_rate: 24.470000% currently going to do 65 epochs\n",
      "After epoch 51: averaged train_err_rate: 8.940000% averaged train nll: 0.306285 averaged train loss: 0.860016\n",
      "At minibatch 81700, batch loss 0.955462, batch nll 0.400934, batch error rate 16.000000%\n",
      "At minibatch 81800, batch loss 0.748048, batch nll 0.194226, batch error rate 4.000000%\n",
      "At minibatch 81900, batch loss 0.857645, batch nll 0.303611, batch error rate 12.000000%\n",
      "At minibatch 82000, batch loss 0.894699, batch nll 0.340216, batch error rate 12.000000%\n",
      "At minibatch 82100, batch loss 0.796773, batch nll 0.242012, batch error rate 12.000000%\n",
      "At minibatch 82200, batch loss 1.000368, batch nll 0.445454, batch error rate 12.000000%\n",
      "At minibatch 82300, batch loss 0.747776, batch nll 0.193237, batch error rate 4.000000%\n",
      "At minibatch 82400, batch loss 0.920789, batch nll 0.365883, batch error rate 16.000000%\n",
      "At minibatch 82500, batch loss 0.906482, batch nll 0.351352, batch error rate 12.000000%\n",
      "At minibatch 82600, batch loss 0.739953, batch nll 0.184765, batch error rate 4.000000%\n",
      "At minibatch 82700, batch loss 0.722806, batch nll 0.166856, batch error rate 8.000000%\n",
      "At minibatch 82800, batch loss 0.757093, batch nll 0.201579, batch error rate 4.000000%\n",
      "At minibatch 82900, batch loss 1.068010, batch nll 0.512471, batch error rate 16.000000%\n",
      "At minibatch 83000, batch loss 1.112911, batch nll 0.557330, batch error rate 20.000000%\n",
      "At minibatch 83100, batch loss 0.864759, batch nll 0.309078, batch error rate 8.000000%\n",
      "At minibatch 83200, batch loss 1.070503, batch nll 0.514635, batch error rate 20.000000%\n",
      "After epoch 52: valid_err_rate: 24.860000% currently going to do 65 epochs\n",
      "After epoch 52: averaged train_err_rate: 9.127500% averaged train nll: 0.305445 averaged train loss: 0.860414\n",
      "At minibatch 83300, batch loss 0.794337, batch nll 0.238050, batch error rate 4.000000%\n",
      "At minibatch 83400, batch loss 1.015737, batch nll 0.460311, batch error rate 24.000000%\n",
      "At minibatch 83500, batch loss 0.896883, batch nll 0.341698, batch error rate 12.000000%\n",
      "At minibatch 83600, batch loss 0.818794, batch nll 0.263840, batch error rate 12.000000%\n",
      "At minibatch 83700, batch loss 0.905598, batch nll 0.350763, batch error rate 8.000000%\n",
      "At minibatch 83800, batch loss 1.009968, batch nll 0.455124, batch error rate 16.000000%\n",
      "At minibatch 83900, batch loss 0.746758, batch nll 0.192248, batch error rate 4.000000%\n",
      "At minibatch 84000, batch loss 0.965062, batch nll 0.409675, batch error rate 4.000000%\n",
      "At minibatch 84100, batch loss 0.826189, batch nll 0.270449, batch error rate 4.000000%\n",
      "At minibatch 84200, batch loss 0.694191, batch nll 0.138765, batch error rate 0.000000%\n",
      "At minibatch 84300, batch loss 0.962876, batch nll 0.408124, batch error rate 20.000000%\n",
      "At minibatch 84400, batch loss 0.992567, batch nll 0.436310, batch error rate 12.000000%\n",
      "At minibatch 84500, batch loss 0.857926, batch nll 0.301732, batch error rate 20.000000%\n",
      "At minibatch 84600, batch loss 0.767619, batch nll 0.211274, batch error rate 4.000000%\n",
      "At minibatch 84700, batch loss 1.075305, batch nll 0.519125, batch error rate 20.000000%\n",
      "At minibatch 84800, batch loss 0.919890, batch nll 0.363404, batch error rate 12.000000%\n",
      "After epoch 53: valid_err_rate: 23.740000% currently going to do 65 epochs\n",
      "After epoch 53: averaged train_err_rate: 8.712500% averaged train nll: 0.297262 averaged train loss: 0.852780\n",
      "At minibatch 84900, batch loss 0.789569, batch nll 0.233521, batch error rate 0.000000%\n",
      "At minibatch 85000, batch loss 0.803329, batch nll 0.247113, batch error rate 8.000000%\n",
      "At minibatch 85100, batch loss 0.863569, batch nll 0.307975, batch error rate 12.000000%\n",
      "At minibatch 85200, batch loss 0.902625, batch nll 0.346887, batch error rate 16.000000%\n",
      "At minibatch 85300, batch loss 0.932555, batch nll 0.376162, batch error rate 4.000000%\n",
      "At minibatch 85400, batch loss 0.871281, batch nll 0.314875, batch error rate 12.000000%\n",
      "At minibatch 85500, batch loss 0.796150, batch nll 0.239350, batch error rate 8.000000%\n",
      "At minibatch 85600, batch loss 0.924728, batch nll 0.368071, batch error rate 12.000000%\n",
      "At minibatch 85700, batch loss 0.814860, batch nll 0.258588, batch error rate 4.000000%\n",
      "At minibatch 85800, batch loss 0.796668, batch nll 0.240408, batch error rate 12.000000%\n",
      "At minibatch 85900, batch loss 0.911777, batch nll 0.355708, batch error rate 12.000000%\n",
      "At minibatch 86000, batch loss 0.705811, batch nll 0.149232, batch error rate 0.000000%\n",
      "At minibatch 86100, batch loss 0.733796, batch nll 0.176843, batch error rate 4.000000%\n",
      "At minibatch 86200, batch loss 0.810191, batch nll 0.253052, batch error rate 8.000000%\n",
      "At minibatch 86300, batch loss 0.928935, batch nll 0.371822, batch error rate 12.000000%\n",
      "At minibatch 86400, batch loss 0.652898, batch nll 0.096050, batch error rate 4.000000%\n",
      "After epoch 54: valid_err_rate: 24.180000% currently going to do 65 epochs\n",
      "After epoch 54: averaged train_err_rate: 8.287500% averaged train nll: 0.288294 averaged train loss: 0.844746\n",
      "At minibatch 86500, batch loss 0.751053, batch nll 0.194227, batch error rate 4.000000%\n",
      "At minibatch 86600, batch loss 0.760659, batch nll 0.204375, batch error rate 4.000000%\n",
      "At minibatch 86700, batch loss 0.758115, batch nll 0.202074, batch error rate 4.000000%\n",
      "At minibatch 86800, batch loss 0.709797, batch nll 0.153662, batch error rate 4.000000%\n",
      "At minibatch 86900, batch loss 0.861223, batch nll 0.304524, batch error rate 12.000000%\n",
      "At minibatch 87000, batch loss 0.899215, batch nll 0.343128, batch error rate 12.000000%\n",
      "At minibatch 87100, batch loss 0.716780, batch nll 0.160305, batch error rate 4.000000%\n",
      "At minibatch 87200, batch loss 0.933877, batch nll 0.376954, batch error rate 12.000000%\n",
      "At minibatch 87300, batch loss 0.771793, batch nll 0.214237, batch error rate 4.000000%\n",
      "At minibatch 87400, batch loss 0.972852, batch nll 0.415362, batch error rate 8.000000%\n",
      "At minibatch 87500, batch loss 0.803513, batch nll 0.245788, batch error rate 4.000000%\n",
      "At minibatch 87600, batch loss 0.765596, batch nll 0.207640, batch error rate 0.000000%\n",
      "At minibatch 87700, batch loss 0.781358, batch nll 0.223801, batch error rate 4.000000%\n",
      "At minibatch 87800, batch loss 0.720879, batch nll 0.162712, batch error rate 0.000000%\n",
      "At minibatch 87900, batch loss 0.843911, batch nll 0.285691, batch error rate 8.000000%\n",
      "At minibatch 88000, batch loss 0.857985, batch nll 0.300113, batch error rate 8.000000%\n",
      "After epoch 55: valid_err_rate: 24.530000% currently going to do 65 epochs\n",
      "After epoch 55: averaged train_err_rate: 8.385000% averaged train nll: 0.286965 averaged train loss: 0.844024\n",
      "At minibatch 88100, batch loss 0.686537, batch nll 0.128104, batch error rate 4.000000%\n",
      "At minibatch 88200, batch loss 0.952651, batch nll 0.394303, batch error rate 12.000000%\n",
      "At minibatch 88300, batch loss 0.694225, batch nll 0.135873, batch error rate 0.000000%\n",
      "At minibatch 88400, batch loss 0.664243, batch nll 0.106762, batch error rate 4.000000%\n",
      "At minibatch 88500, batch loss 0.795833, batch nll 0.238622, batch error rate 12.000000%\n",
      "At minibatch 88600, batch loss 0.848480, batch nll 0.291933, batch error rate 4.000000%\n",
      "At minibatch 88700, batch loss 1.015518, batch nll 0.459437, batch error rate 24.000000%\n",
      "At minibatch 88800, batch loss 0.894835, batch nll 0.338810, batch error rate 12.000000%\n",
      "At minibatch 88900, batch loss 0.848624, batch nll 0.291883, batch error rate 12.000000%\n",
      "At minibatch 89000, batch loss 0.924712, batch nll 0.367469, batch error rate 12.000000%\n",
      "At minibatch 89100, batch loss 0.861964, batch nll 0.304704, batch error rate 16.000000%\n",
      "At minibatch 89200, batch loss 0.900725, batch nll 0.343224, batch error rate 12.000000%\n",
      "At minibatch 89300, batch loss 0.755029, batch nll 0.197398, batch error rate 4.000000%\n",
      "At minibatch 89400, batch loss 0.735587, batch nll 0.177956, batch error rate 4.000000%\n",
      "At minibatch 89500, batch loss 0.948951, batch nll 0.391617, batch error rate 12.000000%\n",
      "At minibatch 89600, batch loss 0.911835, batch nll 0.354292, batch error rate 8.000000%\n",
      "After epoch 56: valid_err_rate: 24.990000% currently going to do 65 epochs\n",
      "After epoch 56: averaged train_err_rate: 7.890000% averaged train nll: 0.279651 averaged train loss: 0.836993\n",
      "At minibatch 89700, batch loss 0.852716, batch nll 0.295639, batch error rate 8.000000%\n",
      "At minibatch 89800, batch loss 0.989260, batch nll 0.432736, batch error rate 20.000000%\n",
      "At minibatch 89900, batch loss 0.796024, batch nll 0.239397, batch error rate 8.000000%\n",
      "At minibatch 90000, batch loss 0.856754, batch nll 0.300071, batch error rate 8.000000%\n",
      "At minibatch 90100, batch loss 0.836753, batch nll 0.279842, batch error rate 4.000000%\n",
      "At minibatch 90200, batch loss 0.772084, batch nll 0.215629, batch error rate 4.000000%\n",
      "At minibatch 90300, batch loss 0.734404, batch nll 0.178048, batch error rate 8.000000%\n",
      "At minibatch 90400, batch loss 0.880412, batch nll 0.324110, batch error rate 8.000000%\n",
      "At minibatch 90500, batch loss 0.823170, batch nll 0.266787, batch error rate 12.000000%\n",
      "At minibatch 90600, batch loss 0.781243, batch nll 0.224478, batch error rate 4.000000%\n",
      "At minibatch 90700, batch loss 0.769778, batch nll 0.213154, batch error rate 0.000000%\n",
      "At minibatch 90800, batch loss 0.702097, batch nll 0.145384, batch error rate 4.000000%\n",
      "At minibatch 90900, batch loss 0.942000, batch nll 0.385349, batch error rate 12.000000%\n",
      "At minibatch 91000, batch loss 0.849004, batch nll 0.292006, batch error rate 8.000000%\n",
      "At minibatch 91100, batch loss 0.835137, batch nll 0.278615, batch error rate 8.000000%\n",
      "At minibatch 91200, batch loss 1.032795, batch nll 0.476327, batch error rate 16.000000%\n",
      "After epoch 57: valid_err_rate: 23.930000% currently going to do 65 epochs\n",
      "After epoch 57: averaged train_err_rate: 7.667500% averaged train nll: 0.273685 averaged train loss: 0.830348\n",
      "At minibatch 91300, batch loss 0.777976, batch nll 0.221516, batch error rate 4.000000%\n",
      "At minibatch 91400, batch loss 0.794935, batch nll 0.238442, batch error rate 8.000000%\n",
      "At minibatch 91500, batch loss 0.725757, batch nll 0.169555, batch error rate 4.000000%\n",
      "At minibatch 91600, batch loss 0.753479, batch nll 0.197414, batch error rate 4.000000%\n",
      "At minibatch 91700, batch loss 0.884565, batch nll 0.328692, batch error rate 16.000000%\n",
      "At minibatch 91800, batch loss 0.757770, batch nll 0.201536, batch error rate 8.000000%\n",
      "At minibatch 91900, batch loss 0.886614, batch nll 0.330622, batch error rate 12.000000%\n",
      "At minibatch 92000, batch loss 0.774775, batch nll 0.218699, batch error rate 0.000000%\n",
      "At minibatch 92100, batch loss 0.857365, batch nll 0.300579, batch error rate 16.000000%\n",
      "At minibatch 92200, batch loss 1.004030, batch nll 0.447016, batch error rate 16.000000%\n",
      "At minibatch 92300, batch loss 0.811744, batch nll 0.254272, batch error rate 8.000000%\n",
      "At minibatch 92400, batch loss 1.047759, batch nll 0.490624, batch error rate 20.000000%\n",
      "At minibatch 92500, batch loss 0.823927, batch nll 0.266671, batch error rate 8.000000%\n",
      "At minibatch 92600, batch loss 0.872971, batch nll 0.316075, batch error rate 8.000000%\n",
      "At minibatch 92700, batch loss 0.918447, batch nll 0.361204, batch error rate 12.000000%\n",
      "At minibatch 92800, batch loss 0.991456, batch nll 0.434201, batch error rate 12.000000%\n",
      "After epoch 58: valid_err_rate: 23.730000% currently going to do 65 epochs\n",
      "After epoch 58: averaged train_err_rate: 7.470000% averaged train nll: 0.270428 averaged train loss: 0.827040\n",
      "At minibatch 92900, batch loss 0.721985, batch nll 0.164291, batch error rate 0.000000%\n",
      "At minibatch 93000, batch loss 1.107373, batch nll 0.549827, batch error rate 16.000000%\n",
      "At minibatch 93100, batch loss 0.829679, batch nll 0.272665, batch error rate 4.000000%\n",
      "At minibatch 93200, batch loss 0.858361, batch nll 0.301464, batch error rate 8.000000%\n",
      "At minibatch 93300, batch loss 0.833636, batch nll 0.277056, batch error rate 8.000000%\n",
      "At minibatch 93400, batch loss 0.885853, batch nll 0.329113, batch error rate 4.000000%\n",
      "At minibatch 93500, batch loss 0.877876, batch nll 0.321631, batch error rate 12.000000%\n",
      "At minibatch 93600, batch loss 0.784883, batch nll 0.228919, batch error rate 8.000000%\n",
      "At minibatch 93700, batch loss 0.882885, batch nll 0.326536, batch error rate 8.000000%\n",
      "At minibatch 93800, batch loss 0.878073, batch nll 0.321503, batch error rate 8.000000%\n",
      "At minibatch 93900, batch loss 0.904834, batch nll 0.347515, batch error rate 16.000000%\n",
      "At minibatch 94000, batch loss 0.896467, batch nll 0.339092, batch error rate 16.000000%\n",
      "At minibatch 94100, batch loss 0.889972, batch nll 0.332619, batch error rate 16.000000%\n",
      "At minibatch 94200, batch loss 0.757053, batch nll 0.199514, batch error rate 8.000000%\n",
      "At minibatch 94300, batch loss 0.912989, batch nll 0.355504, batch error rate 8.000000%\n",
      "At minibatch 94400, batch loss 0.994463, batch nll 0.436930, batch error rate 8.000000%\n",
      "After epoch 59: valid_err_rate: 23.550000% currently going to do 89 epochs\n",
      "After epoch 59: averaged train_err_rate: 7.442500% averaged train nll: 0.265856 averaged train loss: 0.822882\n",
      "At minibatch 94500, batch loss 0.706538, batch nll 0.149794, batch error rate 4.000000%\n",
      "At minibatch 94600, batch loss 1.056604, batch nll 0.500254, batch error rate 16.000000%\n",
      "At minibatch 94700, batch loss 0.753959, batch nll 0.197420, batch error rate 4.000000%\n",
      "At minibatch 94800, batch loss 0.759618, batch nll 0.202992, batch error rate 4.000000%\n",
      "At minibatch 94900, batch loss 0.797720, batch nll 0.241082, batch error rate 8.000000%\n",
      "At minibatch 95000, batch loss 0.889551, batch nll 0.332751, batch error rate 8.000000%\n",
      "At minibatch 95100, batch loss 0.702077, batch nll 0.145409, batch error rate 0.000000%\n",
      "At minibatch 95200, batch loss 0.839737, batch nll 0.283356, batch error rate 4.000000%\n",
      "At minibatch 95300, batch loss 0.746094, batch nll 0.189346, batch error rate 0.000000%\n",
      "At minibatch 95400, batch loss 0.900396, batch nll 0.343450, batch error rate 12.000000%\n",
      "At minibatch 95500, batch loss 0.724012, batch nll 0.166887, batch error rate 0.000000%\n",
      "At minibatch 95600, batch loss 0.730234, batch nll 0.173473, batch error rate 0.000000%\n",
      "At minibatch 95700, batch loss 0.773087, batch nll 0.215734, batch error rate 4.000000%\n",
      "At minibatch 95800, batch loss 0.905544, batch nll 0.348357, batch error rate 16.000000%\n",
      "At minibatch 95900, batch loss 0.892626, batch nll 0.335923, batch error rate 12.000000%\n",
      "At minibatch 96000, batch loss 0.925463, batch nll 0.368477, batch error rate 12.000000%\n",
      "After epoch 60: valid_err_rate: 24.020000% currently going to do 89 epochs\n",
      "After epoch 60: averaged train_err_rate: 6.865000% averaged train nll: 0.258388 averaged train loss: 0.815194\n",
      "At minibatch 96100, batch loss 0.764502, batch nll 0.207392, batch error rate 4.000000%\n",
      "At minibatch 96200, batch loss 0.739808, batch nll 0.182692, batch error rate 8.000000%\n",
      "At minibatch 96300, batch loss 0.762588, batch nll 0.205618, batch error rate 8.000000%\n",
      "At minibatch 96400, batch loss 0.769308, batch nll 0.212447, batch error rate 4.000000%\n",
      "At minibatch 96500, batch loss 0.823330, batch nll 0.266449, batch error rate 4.000000%\n",
      "At minibatch 96600, batch loss 0.891473, batch nll 0.334506, batch error rate 4.000000%\n",
      "At minibatch 96700, batch loss 1.077091, batch nll 0.520616, batch error rate 20.000000%\n",
      "At minibatch 96800, batch loss 0.855749, batch nll 0.299117, batch error rate 8.000000%\n",
      "At minibatch 96900, batch loss 0.817071, batch nll 0.260269, batch error rate 8.000000%\n",
      "At minibatch 97000, batch loss 0.738436, batch nll 0.181403, batch error rate 0.000000%\n",
      "At minibatch 97100, batch loss 0.916499, batch nll 0.358749, batch error rate 8.000000%\n",
      "At minibatch 97200, batch loss 0.906230, batch nll 0.348606, batch error rate 12.000000%\n",
      "At minibatch 97300, batch loss 0.803224, batch nll 0.245574, batch error rate 4.000000%\n",
      "At minibatch 97400, batch loss 0.791284, batch nll 0.234023, batch error rate 8.000000%\n",
      "At minibatch 97500, batch loss 0.743664, batch nll 0.186251, batch error rate 4.000000%\n",
      "At minibatch 97600, batch loss 0.708784, batch nll 0.151424, batch error rate 4.000000%\n",
      "After epoch 61: valid_err_rate: 23.660000% currently going to do 89 epochs\n",
      "After epoch 61: averaged train_err_rate: 7.185000% averaged train nll: 0.261586 averaged train loss: 0.818708\n",
      "At minibatch 97700, batch loss 0.809368, batch nll 0.252799, batch error rate 4.000000%\n",
      "At minibatch 97800, batch loss 0.735278, batch nll 0.179309, batch error rate 4.000000%\n",
      "At minibatch 97900, batch loss 0.843784, batch nll 0.287795, batch error rate 8.000000%\n",
      "At minibatch 98000, batch loss 0.734272, batch nll 0.178404, batch error rate 4.000000%\n",
      "At minibatch 98100, batch loss 0.685337, batch nll 0.129695, batch error rate 0.000000%\n",
      "At minibatch 98200, batch loss 0.830227, batch nll 0.274919, batch error rate 8.000000%\n",
      "At minibatch 98300, batch loss 0.746512, batch nll 0.191244, batch error rate 4.000000%\n",
      "At minibatch 98400, batch loss 0.764462, batch nll 0.209582, batch error rate 8.000000%\n",
      "At minibatch 98500, batch loss 0.771568, batch nll 0.216679, batch error rate 8.000000%\n",
      "At minibatch 98600, batch loss 0.833683, batch nll 0.278719, batch error rate 4.000000%\n",
      "At minibatch 98700, batch loss 0.789286, batch nll 0.234259, batch error rate 4.000000%\n",
      "At minibatch 98800, batch loss 0.713583, batch nll 0.158239, batch error rate 4.000000%\n",
      "At minibatch 98900, batch loss 0.731555, batch nll 0.175944, batch error rate 0.000000%\n",
      "At minibatch 99000, batch loss 0.755451, batch nll 0.200026, batch error rate 8.000000%\n",
      "At minibatch 99100, batch loss 0.967985, batch nll 0.412362, batch error rate 20.000000%\n",
      "At minibatch 99200, batch loss 0.963030, batch nll 0.407385, batch error rate 20.000000%\n",
      "After epoch 62: valid_err_rate: 25.130000% currently going to do 89 epochs\n",
      "After epoch 62: averaged train_err_rate: 6.762500% averaged train nll: 0.250782 averaged train loss: 0.806342\n",
      "At minibatch 99300, batch loss 0.752173, batch nll 0.196791, batch error rate 0.000000%\n",
      "At minibatch 99400, batch loss 0.768544, batch nll 0.213514, batch error rate 8.000000%\n",
      "At minibatch 99500, batch loss 0.685451, batch nll 0.130821, batch error rate 0.000000%\n",
      "At minibatch 99600, batch loss 0.780610, batch nll 0.226047, batch error rate 4.000000%\n",
      "At minibatch 99700, batch loss 1.037634, batch nll 0.483605, batch error rate 20.000000%\n",
      "At minibatch 99800, batch loss 0.741407, batch nll 0.187542, batch error rate 0.000000%\n",
      "At minibatch 99900, batch loss 0.734838, batch nll 0.180510, batch error rate 0.000000%\n",
      "At minibatch 100000, batch loss 0.754008, batch nll 0.199788, batch error rate 4.000000%\n",
      "At minibatch 100100, batch loss 1.066807, batch nll 0.512290, batch error rate 20.000000%\n",
      "At minibatch 100200, batch loss 0.736872, batch nll 0.182127, batch error rate 0.000000%\n",
      "At minibatch 100300, batch loss 0.866633, batch nll 0.311838, batch error rate 8.000000%\n",
      "At minibatch 100400, batch loss 0.801445, batch nll 0.247055, batch error rate 4.000000%\n",
      "At minibatch 100500, batch loss 1.078231, batch nll 0.523468, batch error rate 20.000000%\n",
      "At minibatch 100600, batch loss 0.921753, batch nll 0.366812, batch error rate 8.000000%\n",
      "At minibatch 100700, batch loss 1.059788, batch nll 0.505074, batch error rate 12.000000%\n",
      "At minibatch 100800, batch loss 0.794526, batch nll 0.239510, batch error rate 0.000000%\n",
      "After epoch 63: valid_err_rate: 24.840000% currently going to do 89 epochs\n",
      "After epoch 63: averaged train_err_rate: 6.502500% averaged train nll: 0.248986 averaged train loss: 0.803571\n",
      "At minibatch 100900, batch loss 0.718175, batch nll 0.162993, batch error rate 4.000000%\n",
      "At minibatch 101000, batch loss 0.751450, batch nll 0.196619, batch error rate 0.000000%\n",
      "At minibatch 101100, batch loss 0.874915, batch nll 0.320739, batch error rate 8.000000%\n",
      "At minibatch 101200, batch loss 0.766627, batch nll 0.212319, batch error rate 8.000000%\n",
      "At minibatch 101300, batch loss 1.003759, batch nll 0.449887, batch error rate 24.000000%\n",
      "At minibatch 101400, batch loss 0.774876, batch nll 0.220652, batch error rate 4.000000%\n",
      "At minibatch 101500, batch loss 0.720360, batch nll 0.166928, batch error rate 4.000000%\n",
      "At minibatch 101600, batch loss 0.714820, batch nll 0.161243, batch error rate 0.000000%\n",
      "At minibatch 101700, batch loss 0.689627, batch nll 0.135575, batch error rate 0.000000%\n",
      "At minibatch 101800, batch loss 0.828140, batch nll 0.273575, batch error rate 8.000000%\n",
      "At minibatch 101900, batch loss 0.697545, batch nll 0.143385, batch error rate 4.000000%\n",
      "At minibatch 102000, batch loss 0.877875, batch nll 0.323617, batch error rate 8.000000%\n",
      "At minibatch 102100, batch loss 0.908507, batch nll 0.353835, batch error rate 12.000000%\n",
      "At minibatch 102200, batch loss 0.691975, batch nll 0.136965, batch error rate 0.000000%\n",
      "At minibatch 102300, batch loss 0.928755, batch nll 0.373398, batch error rate 12.000000%\n",
      "At minibatch 102400, batch loss 0.882505, batch nll 0.327228, batch error rate 16.000000%\n",
      "After epoch 64: valid_err_rate: 25.000000% currently going to do 89 epochs\n",
      "After epoch 64: averaged train_err_rate: 6.490000% averaged train nll: 0.246719 averaged train loss: 0.801151\n",
      "At minibatch 102500, batch loss 0.749682, batch nll 0.194538, batch error rate 4.000000%\n",
      "At minibatch 102600, batch loss 0.708625, batch nll 0.154275, batch error rate 0.000000%\n",
      "At minibatch 102700, batch loss 0.765128, batch nll 0.211327, batch error rate 4.000000%\n",
      "At minibatch 102800, batch loss 0.788783, batch nll 0.235283, batch error rate 8.000000%\n",
      "At minibatch 102900, batch loss 0.899430, batch nll 0.345844, batch error rate 12.000000%\n",
      "At minibatch 103000, batch loss 0.799920, batch nll 0.246112, batch error rate 4.000000%\n",
      "At minibatch 103100, batch loss 0.772891, batch nll 0.218697, batch error rate 4.000000%\n",
      "At minibatch 103200, batch loss 0.772786, batch nll 0.218082, batch error rate 4.000000%\n",
      "At minibatch 103300, batch loss 0.808958, batch nll 0.254638, batch error rate 8.000000%\n",
      "At minibatch 103400, batch loss 0.823293, batch nll 0.269175, batch error rate 8.000000%\n",
      "At minibatch 103500, batch loss 0.712250, batch nll 0.158184, batch error rate 0.000000%\n",
      "At minibatch 103600, batch loss 0.689763, batch nll 0.135459, batch error rate 0.000000%\n",
      "At minibatch 103700, batch loss 0.710729, batch nll 0.156030, batch error rate 4.000000%\n",
      "At minibatch 103800, batch loss 0.837792, batch nll 0.283188, batch error rate 12.000000%\n",
      "At minibatch 103900, batch loss 0.765531, batch nll 0.210784, batch error rate 4.000000%\n",
      "At minibatch 104000, batch loss 0.727347, batch nll 0.172914, batch error rate 4.000000%\n",
      "After epoch 65: valid_err_rate: 24.220000% currently going to do 89 epochs\n",
      "After epoch 65: averaged train_err_rate: 6.145000% averaged train nll: 0.240303 averaged train loss: 0.794611\n",
      "At minibatch 104100, batch loss 0.708958, batch nll 0.154614, batch error rate 0.000000%\n",
      "At minibatch 104200, batch loss 0.739419, batch nll 0.185402, batch error rate 8.000000%\n",
      "At minibatch 104300, batch loss 0.696006, batch nll 0.142192, batch error rate 0.000000%\n",
      "At minibatch 104400, batch loss 0.764396, batch nll 0.210861, batch error rate 8.000000%\n",
      "At minibatch 104500, batch loss 0.854034, batch nll 0.300612, batch error rate 12.000000%\n",
      "At minibatch 104600, batch loss 0.752864, batch nll 0.199106, batch error rate 0.000000%\n",
      "At minibatch 104700, batch loss 0.754238, batch nll 0.199941, batch error rate 8.000000%\n",
      "At minibatch 104800, batch loss 0.891269, batch nll 0.336718, batch error rate 8.000000%\n",
      "At minibatch 104900, batch loss 0.823629, batch nll 0.268546, batch error rate 4.000000%\n",
      "At minibatch 105000, batch loss 0.701604, batch nll 0.147009, batch error rate 4.000000%\n",
      "At minibatch 105100, batch loss 0.758342, batch nll 0.203801, batch error rate 8.000000%\n",
      "At minibatch 105200, batch loss 0.844963, batch nll 0.290572, batch error rate 4.000000%\n",
      "At minibatch 105300, batch loss 0.695353, batch nll 0.140883, batch error rate 0.000000%\n",
      "At minibatch 105400, batch loss 0.813872, batch nll 0.259367, batch error rate 8.000000%\n",
      "At minibatch 105500, batch loss 0.746117, batch nll 0.191638, batch error rate 4.000000%\n",
      "At minibatch 105600, batch loss 0.822620, batch nll 0.268452, batch error rate 4.000000%\n",
      "After epoch 66: valid_err_rate: 23.600000% currently going to do 89 epochs\n",
      "After epoch 66: averaged train_err_rate: 6.272500% averaged train nll: 0.238763 averaged train loss: 0.793008\n",
      "At minibatch 105700, batch loss 0.746749, batch nll 0.192621, batch error rate 8.000000%\n",
      "At minibatch 105800, batch loss 0.691590, batch nll 0.137752, batch error rate 4.000000%\n",
      "At minibatch 105900, batch loss 0.712755, batch nll 0.159206, batch error rate 0.000000%\n",
      "At minibatch 106000, batch loss 0.779419, batch nll 0.225867, batch error rate 8.000000%\n",
      "At minibatch 106100, batch loss 0.716126, batch nll 0.163026, batch error rate 4.000000%\n",
      "At minibatch 106200, batch loss 0.637803, batch nll 0.085004, batch error rate 0.000000%\n",
      "At minibatch 106300, batch loss 0.728930, batch nll 0.176867, batch error rate 4.000000%\n",
      "At minibatch 106400, batch loss 0.948349, batch nll 0.396485, batch error rate 20.000000%\n",
      "At minibatch 106500, batch loss 0.798097, batch nll 0.246101, batch error rate 8.000000%\n",
      "At minibatch 106600, batch loss 0.932360, batch nll 0.380209, batch error rate 12.000000%\n",
      "At minibatch 106700, batch loss 0.748380, batch nll 0.195586, batch error rate 0.000000%\n",
      "At minibatch 106800, batch loss 0.764879, batch nll 0.212508, batch error rate 8.000000%\n",
      "At minibatch 106900, batch loss 0.776171, batch nll 0.223179, batch error rate 4.000000%\n",
      "At minibatch 107000, batch loss 0.869964, batch nll 0.317139, batch error rate 8.000000%\n",
      "At minibatch 107100, batch loss 0.928518, batch nll 0.375450, batch error rate 12.000000%\n",
      "At minibatch 107200, batch loss 0.791208, batch nll 0.238210, batch error rate 4.000000%\n",
      "After epoch 67: valid_err_rate: 24.160000% currently going to do 89 epochs\n",
      "After epoch 67: averaged train_err_rate: 5.857500% averaged train nll: 0.233501 averaged train loss: 0.786395\n",
      "At minibatch 107300, batch loss 0.665316, batch nll 0.112169, batch error rate 4.000000%\n",
      "At minibatch 107400, batch loss 0.883053, batch nll 0.330270, batch error rate 12.000000%\n",
      "At minibatch 107500, batch loss 0.656687, batch nll 0.104232, batch error rate 0.000000%\n",
      "At minibatch 107600, batch loss 0.701643, batch nll 0.149841, batch error rate 4.000000%\n",
      "At minibatch 107700, batch loss 0.774186, batch nll 0.222538, batch error rate 4.000000%\n",
      "At minibatch 107800, batch loss 0.914872, batch nll 0.363219, batch error rate 12.000000%\n",
      "At minibatch 107900, batch loss 0.746367, batch nll 0.194760, batch error rate 8.000000%\n",
      "At minibatch 108000, batch loss 0.693387, batch nll 0.141955, batch error rate 4.000000%\n",
      "At minibatch 108100, batch loss 0.695404, batch nll 0.143659, batch error rate 0.000000%\n",
      "At minibatch 108200, batch loss 0.813733, batch nll 0.261612, batch error rate 4.000000%\n",
      "At minibatch 108300, batch loss 0.812458, batch nll 0.259994, batch error rate 4.000000%\n",
      "At minibatch 108400, batch loss 0.842836, batch nll 0.290706, batch error rate 16.000000%\n",
      "At minibatch 108500, batch loss 0.806690, batch nll 0.254686, batch error rate 4.000000%\n",
      "At minibatch 108600, batch loss 0.791897, batch nll 0.239565, batch error rate 4.000000%\n",
      "At minibatch 108700, batch loss 0.826617, batch nll 0.273985, batch error rate 4.000000%\n",
      "At minibatch 108800, batch loss 0.789208, batch nll 0.236161, batch error rate 4.000000%\n",
      "After epoch 68: valid_err_rate: 24.230000% currently going to do 89 epochs\n",
      "After epoch 68: averaged train_err_rate: 5.747500% averaged train nll: 0.230425 averaged train loss: 0.782608\n",
      "At minibatch 108900, batch loss 0.693326, batch nll 0.140752, batch error rate 0.000000%\n",
      "At minibatch 109000, batch loss 0.717192, batch nll 0.165047, batch error rate 4.000000%\n",
      "At minibatch 109100, batch loss 0.671414, batch nll 0.119751, batch error rate 0.000000%\n",
      "At minibatch 109200, batch loss 0.685352, batch nll 0.133464, batch error rate 0.000000%\n",
      "At minibatch 109300, batch loss 0.768524, batch nll 0.216556, batch error rate 4.000000%\n",
      "At minibatch 109400, batch loss 0.711858, batch nll 0.159577, batch error rate 0.000000%\n",
      "At minibatch 109500, batch loss 0.760497, batch nll 0.207636, batch error rate 8.000000%\n",
      "At minibatch 109600, batch loss 0.885679, batch nll 0.332738, batch error rate 8.000000%\n",
      "At minibatch 109700, batch loss 0.718864, batch nll 0.166011, batch error rate 0.000000%\n",
      "At minibatch 109800, batch loss 0.713952, batch nll 0.160934, batch error rate 0.000000%\n",
      "At minibatch 109900, batch loss 0.785458, batch nll 0.232769, batch error rate 8.000000%\n",
      "At minibatch 110000, batch loss 0.837358, batch nll 0.284837, batch error rate 16.000000%\n",
      "At minibatch 110100, batch loss 0.847114, batch nll 0.294350, batch error rate 8.000000%\n",
      "At minibatch 110200, batch loss 0.876894, batch nll 0.323962, batch error rate 12.000000%\n",
      "At minibatch 110300, batch loss 0.954633, batch nll 0.402031, batch error rate 20.000000%\n",
      "At minibatch 110400, batch loss 0.868861, batch nll 0.316218, batch error rate 20.000000%\n",
      "After epoch 69: valid_err_rate: 25.660000% currently going to do 89 epochs\n",
      "After epoch 69: averaged train_err_rate: 5.627500% averaged train nll: 0.228478 averaged train loss: 0.781015\n",
      "At minibatch 110500, batch loss 0.698712, batch nll 0.146351, batch error rate 0.000000%\n",
      "At minibatch 110600, batch loss 0.674566, batch nll 0.122185, batch error rate 0.000000%\n",
      "At minibatch 110700, batch loss 0.752024, batch nll 0.200045, batch error rate 4.000000%\n",
      "At minibatch 110800, batch loss 0.771453, batch nll 0.219892, batch error rate 0.000000%\n",
      "At minibatch 110900, batch loss 0.732164, batch nll 0.180320, batch error rate 4.000000%\n",
      "At minibatch 111000, batch loss 0.682717, batch nll 0.131172, batch error rate 4.000000%\n",
      "At minibatch 111100, batch loss 0.769432, batch nll 0.218152, batch error rate 4.000000%\n",
      "At minibatch 111200, batch loss 0.725590, batch nll 0.174491, batch error rate 4.000000%\n",
      "At minibatch 111300, batch loss 0.721243, batch nll 0.170005, batch error rate 4.000000%\n",
      "At minibatch 111400, batch loss 0.766741, batch nll 0.215050, batch error rate 4.000000%\n",
      "At minibatch 111500, batch loss 0.833810, batch nll 0.281966, batch error rate 8.000000%\n",
      "At minibatch 111600, batch loss 0.865107, batch nll 0.313366, batch error rate 8.000000%\n",
      "At minibatch 111700, batch loss 0.781154, batch nll 0.228902, batch error rate 4.000000%\n",
      "At minibatch 111800, batch loss 0.781553, batch nll 0.229289, batch error rate 4.000000%\n",
      "At minibatch 111900, batch loss 0.854833, batch nll 0.302472, batch error rate 12.000000%\n",
      "At minibatch 112000, batch loss 0.809687, batch nll 0.257121, batch error rate 12.000000%\n",
      "After epoch 70: valid_err_rate: 25.140000% currently going to do 89 epochs\n",
      "After epoch 70: averaged train_err_rate: 5.727500% averaged train nll: 0.228934 averaged train loss: 0.780820\n",
      "At minibatch 112100, batch loss 0.784913, batch nll 0.232650, batch error rate 8.000000%\n",
      "At minibatch 112200, batch loss 0.776363, batch nll 0.224214, batch error rate 8.000000%\n",
      "At minibatch 112300, batch loss 0.777596, batch nll 0.226040, batch error rate 8.000000%\n",
      "At minibatch 112400, batch loss 0.643453, batch nll 0.091834, batch error rate 0.000000%\n",
      "At minibatch 112500, batch loss 0.732225, batch nll 0.180839, batch error rate 4.000000%\n",
      "At minibatch 112600, batch loss 0.733929, batch nll 0.182923, batch error rate 4.000000%\n",
      "At minibatch 112700, batch loss 0.634089, batch nll 0.083114, batch error rate 0.000000%\n",
      "At minibatch 112800, batch loss 0.804362, batch nll 0.253286, batch error rate 4.000000%\n",
      "At minibatch 112900, batch loss 0.766174, batch nll 0.215020, batch error rate 4.000000%\n",
      "At minibatch 113000, batch loss 0.747822, batch nll 0.196329, batch error rate 4.000000%\n",
      "At minibatch 113100, batch loss 0.792664, batch nll 0.240894, batch error rate 12.000000%\n",
      "At minibatch 113200, batch loss 0.715196, batch nll 0.162839, batch error rate 4.000000%\n",
      "At minibatch 113300, batch loss 0.814172, batch nll 0.262065, batch error rate 8.000000%\n",
      "At minibatch 113400, batch loss 0.837929, batch nll 0.285835, batch error rate 8.000000%\n",
      "At minibatch 113500, batch loss 0.731774, batch nll 0.179658, batch error rate 4.000000%\n",
      "At minibatch 113600, batch loss 0.745744, batch nll 0.193509, batch error rate 0.000000%\n",
      "After epoch 71: valid_err_rate: 24.750000% currently going to do 89 epochs\n",
      "After epoch 71: averaged train_err_rate: 5.557500% averaged train nll: 0.224607 averaged train loss: 0.776330\n",
      "At minibatch 113700, batch loss 0.669947, batch nll 0.117801, batch error rate 0.000000%\n",
      "At minibatch 113800, batch loss 0.760517, batch nll 0.208665, batch error rate 4.000000%\n",
      "At minibatch 113900, batch loss 0.760227, batch nll 0.208557, batch error rate 8.000000%\n",
      "At minibatch 114000, batch loss 0.679612, batch nll 0.128141, batch error rate 4.000000%\n",
      "At minibatch 114100, batch loss 0.775005, batch nll 0.223506, batch error rate 4.000000%\n",
      "At minibatch 114200, batch loss 0.686552, batch nll 0.135245, batch error rate 4.000000%\n",
      "At minibatch 114300, batch loss 0.699524, batch nll 0.148352, batch error rate 0.000000%\n",
      "At minibatch 114400, batch loss 0.753594, batch nll 0.202166, batch error rate 4.000000%\n",
      "At minibatch 114500, batch loss 0.888964, batch nll 0.337886, batch error rate 12.000000%\n",
      "At minibatch 114600, batch loss 0.742719, batch nll 0.192070, batch error rate 8.000000%\n",
      "At minibatch 114700, batch loss 0.814662, batch nll 0.264159, batch error rate 8.000000%\n",
      "At minibatch 114800, batch loss 0.734913, batch nll 0.184670, batch error rate 8.000000%\n",
      "At minibatch 114900, batch loss 0.871503, batch nll 0.321093, batch error rate 12.000000%\n",
      "At minibatch 115000, batch loss 0.824734, batch nll 0.274637, batch error rate 8.000000%\n",
      "At minibatch 115100, batch loss 1.011107, batch nll 0.460762, batch error rate 12.000000%\n",
      "At minibatch 115200, batch loss 0.745864, batch nll 0.195344, batch error rate 0.000000%\n",
      "After epoch 72: valid_err_rate: 23.670000% currently going to do 89 epochs\n",
      "After epoch 72: averaged train_err_rate: 5.242500% averaged train nll: 0.220427 averaged train loss: 0.771495\n",
      "At minibatch 115300, batch loss 0.793640, batch nll 0.243060, batch error rate 8.000000%\n",
      "At minibatch 115400, batch loss 0.752206, batch nll 0.201869, batch error rate 4.000000%\n",
      "At minibatch 115500, batch loss 0.864207, batch nll 0.314030, batch error rate 12.000000%\n",
      "At minibatch 115600, batch loss 0.703980, batch nll 0.154210, batch error rate 0.000000%\n",
      "At minibatch 115700, batch loss 0.818751, batch nll 0.269414, batch error rate 8.000000%\n",
      "At minibatch 115800, batch loss 0.722446, batch nll 0.173309, batch error rate 0.000000%\n",
      "At minibatch 115900, batch loss 0.646245, batch nll 0.097097, batch error rate 0.000000%\n",
      "At minibatch 116000, batch loss 0.711840, batch nll 0.162714, batch error rate 8.000000%\n",
      "At minibatch 116100, batch loss 0.757082, batch nll 0.208348, batch error rate 4.000000%\n",
      "At minibatch 116200, batch loss 0.769922, batch nll 0.220723, batch error rate 4.000000%\n",
      "At minibatch 116300, batch loss 0.885402, batch nll 0.336075, batch error rate 12.000000%\n",
      "At minibatch 116400, batch loss 0.781381, batch nll 0.232026, batch error rate 4.000000%\n",
      "At minibatch 116500, batch loss 0.799478, batch nll 0.249773, batch error rate 12.000000%\n",
      "At minibatch 116600, batch loss 0.908088, batch nll 0.358309, batch error rate 20.000000%\n",
      "At minibatch 116700, batch loss 0.786375, batch nll 0.236259, batch error rate 8.000000%\n",
      "At minibatch 116800, batch loss 0.777751, batch nll 0.227600, batch error rate 8.000000%\n",
      "After epoch 73: valid_err_rate: 25.000000% currently going to do 89 epochs\n",
      "After epoch 73: averaged train_err_rate: 5.110000% averaged train nll: 0.217060 averaged train loss: 0.766720\n",
      "At minibatch 116900, batch loss 0.692438, batch nll 0.142373, batch error rate 0.000000%\n",
      "At minibatch 117000, batch loss 0.765402, batch nll 0.216414, batch error rate 8.000000%\n",
      "At minibatch 117100, batch loss 0.649265, batch nll 0.100580, batch error rate 0.000000%\n",
      "At minibatch 117200, batch loss 0.750696, batch nll 0.202244, batch error rate 0.000000%\n",
      "At minibatch 117300, batch loss 0.745198, batch nll 0.196476, batch error rate 0.000000%\n",
      "At minibatch 117400, batch loss 0.720369, batch nll 0.171948, batch error rate 4.000000%\n",
      "At minibatch 117500, batch loss 0.728409, batch nll 0.180095, batch error rate 0.000000%\n",
      "At minibatch 117600, batch loss 0.670142, batch nll 0.122087, batch error rate 4.000000%\n",
      "At minibatch 117700, batch loss 0.726331, batch nll 0.178107, batch error rate 0.000000%\n",
      "At minibatch 117800, batch loss 0.737702, batch nll 0.189213, batch error rate 4.000000%\n",
      "At minibatch 117900, batch loss 0.822803, batch nll 0.273862, batch error rate 16.000000%\n",
      "At minibatch 118000, batch loss 0.661569, batch nll 0.112688, batch error rate 0.000000%\n",
      "At minibatch 118100, batch loss 0.735909, batch nll 0.186699, batch error rate 8.000000%\n",
      "At minibatch 118200, batch loss 0.779704, batch nll 0.230184, batch error rate 8.000000%\n",
      "At minibatch 118300, batch loss 0.792373, batch nll 0.242573, batch error rate 4.000000%\n",
      "At minibatch 118400, batch loss 1.023331, batch nll 0.473069, batch error rate 12.000000%\n",
      "After epoch 74: valid_err_rate: 25.250000% currently going to do 89 epochs\n",
      "After epoch 74: averaged train_err_rate: 5.170000% averaged train nll: 0.217130 averaged train loss: 0.766066\n",
      "At minibatch 118500, batch loss 0.710255, batch nll 0.159948, batch error rate 0.000000%\n",
      "At minibatch 118600, batch loss 0.712504, batch nll 0.162802, batch error rate 4.000000%\n",
      "At minibatch 118700, batch loss 0.688674, batch nll 0.139801, batch error rate 4.000000%\n",
      "At minibatch 118800, batch loss 0.766487, batch nll 0.217911, batch error rate 0.000000%\n",
      "At minibatch 118900, batch loss 0.864636, batch nll 0.316147, batch error rate 12.000000%\n",
      "At minibatch 119000, batch loss 0.694150, batch nll 0.145799, batch error rate 4.000000%\n",
      "At minibatch 119100, batch loss 0.899474, batch nll 0.351148, batch error rate 8.000000%\n",
      "At minibatch 119200, batch loss 0.784682, batch nll 0.236150, batch error rate 4.000000%\n",
      "At minibatch 119300, batch loss 0.704034, batch nll 0.155331, batch error rate 0.000000%\n",
      "At minibatch 119400, batch loss 0.820280, batch nll 0.271716, batch error rate 4.000000%\n",
      "At minibatch 119500, batch loss 0.872891, batch nll 0.324287, batch error rate 4.000000%\n",
      "At minibatch 119600, batch loss 0.756631, batch nll 0.207881, batch error rate 8.000000%\n",
      "At minibatch 119700, batch loss 0.673638, batch nll 0.124672, batch error rate 0.000000%\n",
      "At minibatch 119800, batch loss 0.704817, batch nll 0.155399, batch error rate 4.000000%\n",
      "At minibatch 119900, batch loss 0.848925, batch nll 0.299216, batch error rate 16.000000%\n",
      "At minibatch 120000, batch loss 0.904971, batch nll 0.354686, batch error rate 12.000000%\n",
      "After epoch 75: valid_err_rate: 25.600000% currently going to do 89 epochs\n",
      "After epoch 75: averaged train_err_rate: 5.027500% averaged train nll: 0.214749 averaged train loss: 0.763792\n",
      "At minibatch 120100, batch loss 0.673967, batch nll 0.123818, batch error rate 0.000000%\n",
      "At minibatch 120200, batch loss 0.785598, batch nll 0.235754, batch error rate 8.000000%\n",
      "At minibatch 120300, batch loss 0.764736, batch nll 0.215400, batch error rate 12.000000%\n",
      "At minibatch 120400, batch loss 0.918839, batch nll 0.369880, batch error rate 16.000000%\n",
      "At minibatch 120500, batch loss 0.744077, batch nll 0.195093, batch error rate 4.000000%\n",
      "At minibatch 120600, batch loss 0.805784, batch nll 0.257084, batch error rate 4.000000%\n",
      "At minibatch 120700, batch loss 0.814376, batch nll 0.266092, batch error rate 8.000000%\n",
      "At minibatch 120800, batch loss 0.813767, batch nll 0.265168, batch error rate 0.000000%\n",
      "At minibatch 120900, batch loss 0.666133, batch nll 0.116841, batch error rate 0.000000%\n",
      "At minibatch 121000, batch loss 0.646613, batch nll 0.097280, batch error rate 0.000000%\n",
      "At minibatch 121100, batch loss 0.709031, batch nll 0.159441, batch error rate 4.000000%\n",
      "At minibatch 121200, batch loss 0.923561, batch nll 0.373694, batch error rate 16.000000%\n",
      "At minibatch 121300, batch loss 0.926576, batch nll 0.376357, batch error rate 16.000000%\n",
      "At minibatch 121400, batch loss 0.723675, batch nll 0.173675, batch error rate 0.000000%\n",
      "At minibatch 121500, batch loss 0.813391, batch nll 0.263242, batch error rate 8.000000%\n",
      "At minibatch 121600, batch loss 0.832672, batch nll 0.282013, batch error rate 8.000000%\n",
      "After epoch 76: valid_err_rate: 25.510000% currently going to do 89 epochs\n",
      "After epoch 76: averaged train_err_rate: 5.275000% averaged train nll: 0.216251 averaged train loss: 0.765731\n",
      "At minibatch 121700, batch loss 0.749368, batch nll 0.199161, batch error rate 8.000000%\n",
      "At minibatch 121800, batch loss 0.725986, batch nll 0.176601, batch error rate 0.000000%\n",
      "At minibatch 121900, batch loss 0.718216, batch nll 0.169754, batch error rate 0.000000%\n",
      "At minibatch 122000, batch loss 0.805235, batch nll 0.256985, batch error rate 8.000000%\n",
      "At minibatch 122100, batch loss 0.717749, batch nll 0.169779, batch error rate 4.000000%\n",
      "At minibatch 122200, batch loss 0.750414, batch nll 0.202096, batch error rate 4.000000%\n",
      "At minibatch 122300, batch loss 0.767583, batch nll 0.219709, batch error rate 8.000000%\n",
      "At minibatch 122400, batch loss 0.742655, batch nll 0.194831, batch error rate 0.000000%\n",
      "At minibatch 122500, batch loss 0.810108, batch nll 0.262295, batch error rate 8.000000%\n",
      "At minibatch 122600, batch loss 0.829880, batch nll 0.281828, batch error rate 8.000000%\n",
      "At minibatch 122700, batch loss 0.897508, batch nll 0.349570, batch error rate 8.000000%\n",
      "At minibatch 122800, batch loss 0.686024, batch nll 0.137654, batch error rate 0.000000%\n",
      "At minibatch 122900, batch loss 0.703886, batch nll 0.155337, batch error rate 0.000000%\n",
      "At minibatch 123000, batch loss 0.766511, batch nll 0.218263, batch error rate 4.000000%\n",
      "At minibatch 123100, batch loss 0.653945, batch nll 0.105399, batch error rate 0.000000%\n",
      "At minibatch 123200, batch loss 0.845571, batch nll 0.296887, batch error rate 12.000000%\n",
      "After epoch 77: valid_err_rate: 25.740000% currently going to do 89 epochs\n",
      "After epoch 77: averaged train_err_rate: 4.535000% averaged train nll: 0.204677 averaged train loss: 0.753149\n",
      "At minibatch 123300, batch loss 0.753634, batch nll 0.205407, batch error rate 4.000000%\n",
      "At minibatch 123400, batch loss 0.819747, batch nll 0.272053, batch error rate 4.000000%\n",
      "At minibatch 123500, batch loss 0.819181, batch nll 0.271931, batch error rate 4.000000%\n",
      "At minibatch 123600, batch loss 0.673329, batch nll 0.126127, batch error rate 0.000000%\n",
      "At minibatch 123700, batch loss 0.685133, batch nll 0.138149, batch error rate 4.000000%\n",
      "At minibatch 123800, batch loss 0.825729, batch nll 0.279049, batch error rate 16.000000%\n",
      "At minibatch 123900, batch loss 0.802731, batch nll 0.256326, batch error rate 4.000000%\n",
      "At minibatch 124000, batch loss 0.691979, batch nll 0.145365, batch error rate 0.000000%\n",
      "At minibatch 124100, batch loss 0.743898, batch nll 0.197422, batch error rate 0.000000%\n",
      "At minibatch 124200, batch loss 0.724406, batch nll 0.177618, batch error rate 0.000000%\n",
      "At minibatch 124300, batch loss 0.727206, batch nll 0.180153, batch error rate 4.000000%\n",
      "At minibatch 124400, batch loss 0.745261, batch nll 0.198329, batch error rate 0.000000%\n",
      "At minibatch 124500, batch loss 0.888119, batch nll 0.340808, batch error rate 16.000000%\n",
      "At minibatch 124600, batch loss 0.700617, batch nll 0.153305, batch error rate 4.000000%\n",
      "At minibatch 124700, batch loss 0.727383, batch nll 0.179693, batch error rate 4.000000%\n",
      "At minibatch 124800, batch loss 0.884073, batch nll 0.335804, batch error rate 16.000000%\n",
      "After epoch 78: valid_err_rate: 25.690000% currently going to do 89 epochs\n",
      "After epoch 78: averaged train_err_rate: 4.582500% averaged train nll: 0.206505 averaged train loss: 0.753692\n",
      "At minibatch 124900, batch loss 0.677406, batch nll 0.129465, batch error rate 4.000000%\n",
      "At minibatch 125000, batch loss 0.640882, batch nll 0.093568, batch error rate 0.000000%\n",
      "At minibatch 125100, batch loss 0.758230, batch nll 0.211206, batch error rate 8.000000%\n",
      "At minibatch 125200, batch loss 0.734199, batch nll 0.187324, batch error rate 0.000000%\n",
      "At minibatch 125300, batch loss 0.670421, batch nll 0.123356, batch error rate 0.000000%\n",
      "At minibatch 125400, batch loss 0.771098, batch nll 0.224235, batch error rate 4.000000%\n",
      "At minibatch 125500, batch loss 0.786013, batch nll 0.239270, batch error rate 8.000000%\n",
      "At minibatch 125600, batch loss 0.720764, batch nll 0.174597, batch error rate 4.000000%\n",
      "At minibatch 125700, batch loss 0.706331, batch nll 0.160432, batch error rate 4.000000%\n",
      "At minibatch 125800, batch loss 1.109058, batch nll 0.563042, batch error rate 24.000000%\n",
      "At minibatch 125900, batch loss 0.672078, batch nll 0.125529, batch error rate 0.000000%\n",
      "At minibatch 126000, batch loss 0.728864, batch nll 0.182378, batch error rate 0.000000%\n",
      "At minibatch 126100, batch loss 0.810679, batch nll 0.264112, batch error rate 4.000000%\n",
      "At minibatch 126200, batch loss 0.750756, batch nll 0.203779, batch error rate 4.000000%\n",
      "At minibatch 126300, batch loss 0.691344, batch nll 0.143943, batch error rate 0.000000%\n",
      "At minibatch 126400, batch loss 0.746673, batch nll 0.198743, batch error rate 4.000000%\n",
      "After epoch 79: valid_err_rate: 25.060000% currently going to do 89 epochs\n",
      "After epoch 79: averaged train_err_rate: 4.550000% averaged train nll: 0.204670 averaged train loss: 0.751551\n",
      "At minibatch 126500, batch loss 0.637577, batch nll 0.089974, batch error rate 0.000000%\n",
      "At minibatch 126600, batch loss 0.702507, batch nll 0.155026, batch error rate 0.000000%\n",
      "At minibatch 126700, batch loss 0.710178, batch nll 0.163140, batch error rate 0.000000%\n",
      "At minibatch 126800, batch loss 0.697224, batch nll 0.150484, batch error rate 4.000000%\n",
      "At minibatch 126900, batch loss 0.732596, batch nll 0.185924, batch error rate 8.000000%\n",
      "At minibatch 127000, batch loss 0.703245, batch nll 0.156680, batch error rate 4.000000%\n",
      "At minibatch 127100, batch loss 0.728357, batch nll 0.182271, batch error rate 0.000000%\n",
      "At minibatch 127200, batch loss 0.777251, batch nll 0.231040, batch error rate 4.000000%\n",
      "At minibatch 127300, batch loss 0.694442, batch nll 0.148329, batch error rate 4.000000%\n",
      "At minibatch 127400, batch loss 0.859610, batch nll 0.313610, batch error rate 4.000000%\n",
      "At minibatch 127500, batch loss 0.699218, batch nll 0.153292, batch error rate 4.000000%\n",
      "At minibatch 127600, batch loss 0.814305, batch nll 0.268647, batch error rate 8.000000%\n",
      "At minibatch 127700, batch loss 0.779486, batch nll 0.233525, batch error rate 4.000000%\n",
      "At minibatch 127800, batch loss 0.716408, batch nll 0.170440, batch error rate 0.000000%\n",
      "At minibatch 127900, batch loss 0.787554, batch nll 0.241331, batch error rate 8.000000%\n",
      "At minibatch 128000, batch loss 0.776899, batch nll 0.230442, batch error rate 8.000000%\n",
      "After epoch 80: valid_err_rate: 24.110000% currently going to do 89 epochs\n",
      "After epoch 80: averaged train_err_rate: 4.405000% averaged train nll: 0.199367 averaged train loss: 0.745826\n",
      "At minibatch 128100, batch loss 1.014275, batch nll 0.468105, batch error rate 12.000000%\n",
      "At minibatch 128200, batch loss 0.638944, batch nll 0.093003, batch error rate 0.000000%\n",
      "At minibatch 128300, batch loss 0.708149, batch nll 0.162432, batch error rate 4.000000%\n",
      "At minibatch 128400, batch loss 0.736335, batch nll 0.191196, batch error rate 4.000000%\n",
      "At minibatch 128500, batch loss 0.753430, batch nll 0.208654, batch error rate 0.000000%\n",
      "At minibatch 128600, batch loss 0.783981, batch nll 0.239282, batch error rate 8.000000%\n",
      "At minibatch 128700, batch loss 0.802791, batch nll 0.258539, batch error rate 4.000000%\n",
      "At minibatch 128800, batch loss 0.675935, batch nll 0.131464, batch error rate 0.000000%\n",
      "At minibatch 128900, batch loss 0.944387, batch nll 0.400414, batch error rate 12.000000%\n",
      "At minibatch 129000, batch loss 0.626751, batch nll 0.082202, batch error rate 0.000000%\n",
      "At minibatch 129100, batch loss 0.689643, batch nll 0.145004, batch error rate 0.000000%\n",
      "At minibatch 129200, batch loss 0.962900, batch nll 0.418067, batch error rate 12.000000%\n",
      "At minibatch 129300, batch loss 0.725626, batch nll 0.180194, batch error rate 0.000000%\n",
      "At minibatch 129400, batch loss 0.804857, batch nll 0.259392, batch error rate 8.000000%\n",
      "At minibatch 129500, batch loss 0.873613, batch nll 0.328146, batch error rate 12.000000%\n",
      "At minibatch 129600, batch loss 0.810756, batch nll 0.265411, batch error rate 4.000000%\n",
      "After epoch 81: valid_err_rate: 24.180000% currently going to do 89 epochs\n",
      "After epoch 81: averaged train_err_rate: 4.245000% averaged train nll: 0.197130 averaged train loss: 0.742211\n",
      "At minibatch 129700, batch loss 0.704405, batch nll 0.159384, batch error rate 4.000000%\n",
      "At minibatch 129800, batch loss 0.656674, batch nll 0.112378, batch error rate 0.000000%\n",
      "At minibatch 129900, batch loss 0.743555, batch nll 0.199523, batch error rate 4.000000%\n",
      "At minibatch 130000, batch loss 0.792697, batch nll 0.248894, batch error rate 4.000000%\n",
      "At minibatch 130100, batch loss 0.702549, batch nll 0.158580, batch error rate 0.000000%\n",
      "At minibatch 130200, batch loss 0.733073, batch nll 0.189191, batch error rate 4.000000%\n",
      "At minibatch 130300, batch loss 0.754899, batch nll 0.211340, batch error rate 0.000000%\n",
      "At minibatch 130400, batch loss 0.718973, batch nll 0.175339, batch error rate 4.000000%\n",
      "At minibatch 130500, batch loss 0.866029, batch nll 0.322292, batch error rate 12.000000%\n",
      "At minibatch 130600, batch loss 0.713176, batch nll 0.169109, batch error rate 0.000000%\n",
      "At minibatch 130700, batch loss 0.776626, batch nll 0.232414, batch error rate 4.000000%\n",
      "At minibatch 130800, batch loss 0.675288, batch nll 0.131029, batch error rate 4.000000%\n",
      "At minibatch 130900, batch loss 0.722270, batch nll 0.178033, batch error rate 0.000000%\n",
      "At minibatch 131000, batch loss 0.730378, batch nll 0.185671, batch error rate 0.000000%\n",
      "At minibatch 131100, batch loss 0.783763, batch nll 0.239011, batch error rate 8.000000%\n",
      "At minibatch 131200, batch loss 0.755678, batch nll 0.210464, batch error rate 8.000000%\n",
      "After epoch 82: valid_err_rate: 24.310000% currently going to do 89 epochs\n",
      "After epoch 82: averaged train_err_rate: 4.285000% averaged train nll: 0.196615 averaged train loss: 0.740825\n",
      "At minibatch 131300, batch loss 0.805213, batch nll 0.260403, batch error rate 4.000000%\n",
      "At minibatch 131400, batch loss 0.723622, batch nll 0.179322, batch error rate 4.000000%\n",
      "At minibatch 131500, batch loss 0.658640, batch nll 0.114873, batch error rate 0.000000%\n",
      "At minibatch 131600, batch loss 0.672663, batch nll 0.129001, batch error rate 0.000000%\n",
      "At minibatch 131700, batch loss 0.740000, batch nll 0.196325, batch error rate 4.000000%\n",
      "At minibatch 131800, batch loss 0.770889, batch nll 0.227188, batch error rate 12.000000%\n",
      "At minibatch 131900, batch loss 0.739707, batch nll 0.196288, batch error rate 4.000000%\n",
      "At minibatch 132000, batch loss 0.708944, batch nll 0.165673, batch error rate 8.000000%\n",
      "At minibatch 132100, batch loss 0.687697, batch nll 0.144265, batch error rate 0.000000%\n",
      "At minibatch 132200, batch loss 0.692561, batch nll 0.149155, batch error rate 4.000000%\n",
      "At minibatch 132300, batch loss 0.723538, batch nll 0.180033, batch error rate 4.000000%\n",
      "At minibatch 132400, batch loss 0.814281, batch nll 0.270426, batch error rate 4.000000%\n",
      "At minibatch 132500, batch loss 0.758193, batch nll 0.214587, batch error rate 4.000000%\n",
      "At minibatch 132600, batch loss 0.739985, batch nll 0.196276, batch error rate 4.000000%\n",
      "At minibatch 132700, batch loss 0.687150, batch nll 0.143388, batch error rate 0.000000%\n",
      "At minibatch 132800, batch loss 0.743778, batch nll 0.199684, batch error rate 4.000000%\n",
      "After epoch 83: valid_err_rate: 23.850000% currently going to do 89 epochs\n",
      "After epoch 83: averaged train_err_rate: 4.362500% averaged train nll: 0.196258 averaged train loss: 0.740054\n",
      "At minibatch 132900, batch loss 0.637216, batch nll 0.093769, batch error rate 0.000000%\n",
      "At minibatch 133000, batch loss 0.635019, batch nll 0.091929, batch error rate 0.000000%\n",
      "At minibatch 133100, batch loss 0.625466, batch nll 0.082837, batch error rate 0.000000%\n",
      "At minibatch 133200, batch loss 0.655630, batch nll 0.113041, batch error rate 0.000000%\n",
      "At minibatch 133300, batch loss 0.622801, batch nll 0.080312, batch error rate 0.000000%\n",
      "At minibatch 133400, batch loss 0.678834, batch nll 0.136175, batch error rate 0.000000%\n",
      "At minibatch 133500, batch loss 0.865259, batch nll 0.322293, batch error rate 16.000000%\n",
      "At minibatch 133600, batch loss 0.731098, batch nll 0.187900, batch error rate 4.000000%\n",
      "At minibatch 133700, batch loss 0.706032, batch nll 0.162723, batch error rate 0.000000%\n",
      "At minibatch 133800, batch loss 0.812945, batch nll 0.269625, batch error rate 8.000000%\n",
      "At minibatch 133900, batch loss 0.883030, batch nll 0.339830, batch error rate 12.000000%\n",
      "At minibatch 134000, batch loss 0.705589, batch nll 0.162366, batch error rate 4.000000%\n",
      "At minibatch 134100, batch loss 0.703759, batch nll 0.160424, batch error rate 4.000000%\n",
      "At minibatch 134200, batch loss 0.804739, batch nll 0.261382, batch error rate 8.000000%\n",
      "At minibatch 134300, batch loss 0.761238, batch nll 0.217786, batch error rate 4.000000%\n",
      "At minibatch 134400, batch loss 0.841215, batch nll 0.297496, batch error rate 4.000000%\n",
      "After epoch 84: valid_err_rate: 24.480000% currently going to do 89 epochs\n",
      "After epoch 84: averaged train_err_rate: 4.202500% averaged train nll: 0.195489 averaged train loss: 0.738601\n",
      "At minibatch 134500, batch loss 0.838045, batch nll 0.294906, batch error rate 8.000000%\n",
      "At minibatch 134600, batch loss 0.734110, batch nll 0.191233, batch error rate 4.000000%\n",
      "At minibatch 134700, batch loss 0.641178, batch nll 0.098217, batch error rate 0.000000%\n",
      "At minibatch 134800, batch loss 0.747345, batch nll 0.204490, batch error rate 8.000000%\n",
      "At minibatch 134900, batch loss 0.688546, batch nll 0.145977, batch error rate 0.000000%\n",
      "At minibatch 135000, batch loss 0.666866, batch nll 0.124275, batch error rate 0.000000%\n",
      "At minibatch 135100, batch loss 0.789509, batch nll 0.246491, batch error rate 8.000000%\n",
      "At minibatch 135200, batch loss 0.870730, batch nll 0.327394, batch error rate 12.000000%\n",
      "At minibatch 135300, batch loss 0.747525, batch nll 0.203978, batch error rate 4.000000%\n",
      "At minibatch 135400, batch loss 0.721032, batch nll 0.177441, batch error rate 4.000000%\n",
      "At minibatch 135500, batch loss 0.889678, batch nll 0.346272, batch error rate 12.000000%\n",
      "At minibatch 135600, batch loss 0.772945, batch nll 0.229690, batch error rate 4.000000%\n",
      "At minibatch 135700, batch loss 0.719554, batch nll 0.176398, batch error rate 4.000000%\n",
      "At minibatch 135800, batch loss 0.756290, batch nll 0.213065, batch error rate 8.000000%\n",
      "At minibatch 135900, batch loss 0.710033, batch nll 0.166432, batch error rate 0.000000%\n",
      "At minibatch 136000, batch loss 0.956992, batch nll 0.413486, batch error rate 8.000000%\n",
      "After epoch 85: valid_err_rate: 25.230000% currently going to do 89 epochs\n",
      "After epoch 85: averaged train_err_rate: 4.175000% averaged train nll: 0.194306 averaged train loss: 0.737491\n",
      "At minibatch 136100, batch loss 0.706363, batch nll 0.163172, batch error rate 4.000000%\n",
      "At minibatch 136200, batch loss 0.828335, batch nll 0.285638, batch error rate 4.000000%\n",
      "At minibatch 136300, batch loss 0.611738, batch nll 0.069788, batch error rate 0.000000%\n",
      "At minibatch 136400, batch loss 0.645272, batch nll 0.103721, batch error rate 0.000000%\n",
      "At minibatch 136500, batch loss 0.755126, batch nll 0.214326, batch error rate 8.000000%\n",
      "At minibatch 136600, batch loss 0.730391, batch nll 0.189781, batch error rate 8.000000%\n",
      "At minibatch 136700, batch loss 0.796006, batch nll 0.255242, batch error rate 4.000000%\n",
      "At minibatch 136800, batch loss 0.655360, batch nll 0.114424, batch error rate 4.000000%\n",
      "At minibatch 136900, batch loss 0.680640, batch nll 0.139797, batch error rate 0.000000%\n",
      "At minibatch 137000, batch loss 0.839888, batch nll 0.299002, batch error rate 4.000000%\n",
      "At minibatch 137100, batch loss 0.827977, batch nll 0.286890, batch error rate 16.000000%\n",
      "At minibatch 137200, batch loss 0.726550, batch nll 0.185022, batch error rate 8.000000%\n",
      "At minibatch 137300, batch loss 0.804466, batch nll 0.262624, batch error rate 8.000000%\n",
      "At minibatch 137400, batch loss 0.807993, batch nll 0.266085, batch error rate 8.000000%\n",
      "At minibatch 137500, batch loss 0.800127, batch nll 0.257841, batch error rate 4.000000%\n",
      "At minibatch 137600, batch loss 0.810463, batch nll 0.267968, batch error rate 8.000000%\n",
      "After epoch 86: valid_err_rate: 24.680000% currently going to do 89 epochs\n",
      "After epoch 86: averaged train_err_rate: 3.952500% averaged train nll: 0.189307 averaged train loss: 0.730923\n",
      "At minibatch 137700, batch loss 0.648798, batch nll 0.106850, batch error rate 0.000000%\n",
      "At minibatch 137800, batch loss 0.708283, batch nll 0.166643, batch error rate 4.000000%\n",
      "At minibatch 137900, batch loss 0.711740, batch nll 0.170410, batch error rate 0.000000%\n",
      "At minibatch 138000, batch loss 0.607304, batch nll 0.066218, batch error rate 0.000000%\n",
      "At minibatch 138100, batch loss 0.725121, batch nll 0.184249, batch error rate 4.000000%\n",
      "At minibatch 138200, batch loss 0.688814, batch nll 0.148041, batch error rate 0.000000%\n",
      "At minibatch 138300, batch loss 0.604158, batch nll 0.063408, batch error rate 0.000000%\n",
      "At minibatch 138400, batch loss 0.724079, batch nll 0.183144, batch error rate 8.000000%\n",
      "At minibatch 138500, batch loss 0.729544, batch nll 0.188523, batch error rate 0.000000%\n",
      "At minibatch 138600, batch loss 0.802180, batch nll 0.260817, batch error rate 8.000000%\n",
      "At minibatch 138700, batch loss 0.640911, batch nll 0.099596, batch error rate 0.000000%\n",
      "At minibatch 138800, batch loss 0.786780, batch nll 0.245444, batch error rate 4.000000%\n",
      "At minibatch 138900, batch loss 0.768390, batch nll 0.227079, batch error rate 0.000000%\n",
      "At minibatch 139000, batch loss 0.714407, batch nll 0.173071, batch error rate 4.000000%\n",
      "At minibatch 139100, batch loss 0.853270, batch nll 0.311609, batch error rate 8.000000%\n",
      "At minibatch 139200, batch loss 0.721026, batch nll 0.179288, batch error rate 0.000000%\n",
      "After epoch 87: valid_err_rate: 25.520000% currently going to do 89 epochs\n",
      "After epoch 87: averaged train_err_rate: 3.955000% averaged train nll: 0.189804 averaged train loss: 0.731089\n",
      "At minibatch 139300, batch loss 0.626684, batch nll 0.085265, batch error rate 0.000000%\n",
      "At minibatch 139400, batch loss 0.677627, batch nll 0.136601, batch error rate 0.000000%\n",
      "At minibatch 139500, batch loss 0.733079, batch nll 0.192225, batch error rate 8.000000%\n",
      "At minibatch 139600, batch loss 0.807931, batch nll 0.267348, batch error rate 4.000000%\n",
      "At minibatch 139700, batch loss 0.668556, batch nll 0.128465, batch error rate 0.000000%\n",
      "At minibatch 139800, batch loss 0.601316, batch nll 0.061238, batch error rate 0.000000%\n",
      "At minibatch 139900, batch loss 0.715798, batch nll 0.176043, batch error rate 4.000000%\n",
      "At minibatch 140000, batch loss 0.799751, batch nll 0.259830, batch error rate 8.000000%\n",
      "At minibatch 140100, batch loss 0.683961, batch nll 0.143972, batch error rate 0.000000%\n",
      "At minibatch 140200, batch loss 0.738717, batch nll 0.198714, batch error rate 4.000000%\n",
      "At minibatch 140300, batch loss 0.768302, batch nll 0.228287, batch error rate 8.000000%\n",
      "At minibatch 140400, batch loss 0.968654, batch nll 0.428179, batch error rate 16.000000%\n",
      "At minibatch 140500, batch loss 0.761838, batch nll 0.221135, batch error rate 8.000000%\n",
      "At minibatch 140600, batch loss 0.880315, batch nll 0.339128, batch error rate 8.000000%\n",
      "At minibatch 140700, batch loss 0.774651, batch nll 0.233338, batch error rate 4.000000%\n",
      "At minibatch 140800, batch loss 0.758930, batch nll 0.217342, batch error rate 8.000000%\n",
      "After epoch 88: valid_err_rate: 24.440000% currently going to do 89 epochs\n",
      "After epoch 88: averaged train_err_rate: 3.840000% averaged train nll: 0.189010 averaged train loss: 0.729564\n",
      "At minibatch 140900, batch loss 0.818159, batch nll 0.276764, batch error rate 4.000000%\n",
      "At minibatch 141000, batch loss 0.689731, batch nll 0.148536, batch error rate 0.000000%\n",
      "At minibatch 141100, batch loss 0.614692, batch nll 0.073863, batch error rate 0.000000%\n",
      "At minibatch 141200, batch loss 0.779574, batch nll 0.239250, batch error rate 8.000000%\n",
      "At minibatch 141300, batch loss 0.689977, batch nll 0.149927, batch error rate 0.000000%\n",
      "At minibatch 141400, batch loss 0.722105, batch nll 0.182125, batch error rate 4.000000%\n",
      "At minibatch 141500, batch loss 0.796962, batch nll 0.257070, batch error rate 8.000000%\n",
      "At minibatch 141600, batch loss 0.721043, batch nll 0.181161, batch error rate 4.000000%\n",
      "At minibatch 141700, batch loss 0.695522, batch nll 0.155407, batch error rate 4.000000%\n",
      "At minibatch 141800, batch loss 0.704165, batch nll 0.164318, batch error rate 0.000000%\n",
      "At minibatch 141900, batch loss 0.650777, batch nll 0.110827, batch error rate 0.000000%\n",
      "At minibatch 142000, batch loss 0.709119, batch nll 0.169238, batch error rate 4.000000%\n",
      "At minibatch 142100, batch loss 0.748177, batch nll 0.207915, batch error rate 4.000000%\n",
      "At minibatch 142200, batch loss 0.735444, batch nll 0.194900, batch error rate 4.000000%\n",
      "At minibatch 142300, batch loss 0.637060, batch nll 0.096417, batch error rate 0.000000%\n",
      "At minibatch 142400, batch loss 0.733675, batch nll 0.192954, batch error rate 4.000000%\n",
      "After epoch 89: valid_err_rate: 24.530000% currently going to do 89 epochs\n",
      "After epoch 89: averaged train_err_rate: 3.712500% averaged train nll: 0.184425 averaged train loss: 0.724786\n",
      "At minibatch 142500, batch loss 0.737233, batch nll 0.197046, batch error rate 8.000000%\n",
      "At minibatch 142600, batch loss 0.695299, batch nll 0.155554, batch error rate 4.000000%\n",
      "At minibatch 142700, batch loss 0.668953, batch nll 0.129799, batch error rate 0.000000%\n",
      "At minibatch 142800, batch loss 0.592115, batch nll 0.053392, batch error rate 0.000000%\n",
      "At minibatch 142900, batch loss 0.642535, batch nll 0.104106, batch error rate 0.000000%\n",
      "At minibatch 143000, batch loss 0.740497, batch nll 0.202058, batch error rate 4.000000%\n",
      "At minibatch 143100, batch loss 0.718977, batch nll 0.180304, batch error rate 4.000000%\n",
      "At minibatch 143200, batch loss 0.672940, batch nll 0.134009, batch error rate 4.000000%\n",
      "At minibatch 143300, batch loss 0.785690, batch nll 0.247122, batch error rate 4.000000%\n",
      "At minibatch 143400, batch loss 0.825951, batch nll 0.287219, batch error rate 4.000000%\n",
      "At minibatch 143500, batch loss 0.723804, batch nll 0.184683, batch error rate 4.000000%\n",
      "At minibatch 143600, batch loss 0.608344, batch nll 0.069261, batch error rate 0.000000%\n",
      "At minibatch 143700, batch loss 0.771456, batch nll 0.232425, batch error rate 4.000000%\n",
      "At minibatch 143800, batch loss 0.867284, batch nll 0.328143, batch error rate 12.000000%\n",
      "At minibatch 143900, batch loss 0.811460, batch nll 0.271755, batch error rate 4.000000%\n",
      "At minibatch 144000, batch loss 0.707381, batch nll 0.167112, batch error rate 4.000000%\n",
      "After epoch 90: valid_err_rate: 24.960000% currently going to do 89 epochs\n",
      "After epoch 90: averaged train_err_rate: 3.822500% averaged train nll: 0.185055 averaged train loss: 0.724181\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "while e<number_of_epochs: #This loop goes over epochs\n",
    "    e += 1\n",
    "    #First train on all data from this batch\n",
    "    epoch_start_i = i\n",
    "    for X_batch, Y_batch in cifar10_train_stream.get_epoch_iterator(): \n",
    "        i += 1\n",
    "        \n",
    "        K = 10000\n",
    "        lrate = 18e-3 * K / np.maximum(K, i)\n",
    "        momentum=0.9\n",
    "        \n",
    "        L, err_rate, nll, wdec = train_step(X_batch, Y_batch, lrate, momentum)\n",
    "        \n",
    "        #print [p.get_value().ravel()[:10] for p in model_parameters]\n",
    "        #print [p.get_value().ravel()[:10] for p in velocities]\n",
    "        \n",
    "        \n",
    "        train_loss.append((i,L))\n",
    "        train_erros.append((i,err_rate))\n",
    "        train_nll.append((i,nll))\n",
    "        if i % 100 == 0:\n",
    "            print \"At minibatch %d, batch loss %f, batch nll %f, batch error rate %f%%\" % (i, L, nll, err_rate*100)\n",
    "        \n",
    "    # After an epoch compute validation error\n",
    "    val_error_rate = compute_error_rate(cifar10_validation_stream)\n",
    "    if val_error_rate < best_valid_error_rate:\n",
    "        number_of_epochs = np.maximum(number_of_epochs, e * patience_expansion+1)\n",
    "        best_valid_error_rate = val_error_rate\n",
    "        best_params = snapshot_parameters()\n",
    "        best_params_epoch = e\n",
    "    validation_errors.append((i,val_error_rate))\n",
    "    print \"After epoch %d: valid_err_rate: %f%% currently going to do %d epochs\" %(\n",
    "        e, val_error_rate*100, number_of_epochs)\n",
    "    print \"After epoch %d: averaged train_err_rate: %f%% averaged train nll: %f averaged train loss: %f\" %(\n",
    "        e, np.mean(np.asarray(train_erros)[epoch_start_i:,1])*100, \n",
    "        np.mean(np.asarray(train_nll)[epoch_start_i:,1]),\n",
    "        np.mean(np.asarray(train_loss)[epoch_start_i:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting network parameters from after epoch 59\n",
      "Test error rate is 24.250000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe41f8760d0>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEDCAYAAAAvNJM9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe41fbe1ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print \"Setting network parameters from after epoch %d\" %(best_params_epoch)\n",
    "load_parameters(best_params)\n",
    "\n",
    "print \"Test error rate is %f%%\" %(compute_error_rate(cifar10_test_stream)*100.0,)\n",
    "\n",
    "subplot(2,1,1)\n",
    "train_nll_a = np.array(train_nll)\n",
    "semilogy(train_nll_a[:,0], train_nll_a[:,1], label='batch train nll')\n",
    "legend()\n",
    "\n",
    "subplot(2,1,2)\n",
    "train_erros_a = np.array(train_erros)\n",
    "plot(train_erros_a[:,0], train_erros_a[:,1], label='batch train error rate')\n",
    "validation_errors_a = np.array(validation_errors)\n",
    "plot(validation_errors_a[:,0], validation_errors_a[:,1], label='validation error rate', color='r')\n",
    "ylim(0,0.8)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAADqCAYAAACGAX/IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nif8BFn1kQSDPoCwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe423656890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How do the filters in the first layer look like?\n",
    "\n",
    "plot_mat(CW1.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iii = predict.maker.inputs[0]\n",
    "X = iii.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a function that shows how the network processes an image\n",
    "\n",
    "middle_layers_computer = theano.function([X], [\n",
    "        X,\n",
    "        after_C1,\n",
    "        after_P1,\n",
    "        after_C2,\n",
    "        after_P2\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAACWCAYAAAD64bJyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e2a1da890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAEKCAYAAABt+vLPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e2a211d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATYAAAEKCAYAAACYBHl/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nExshJHZwYiOExI7/B5hamm2F+bocAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e2aaca2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAADPCAYAAADRYOtNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRAQM2AAAEBEwYAMAQET4f5GOLEoaamOwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e2ab48c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAADNCAYAAACcqEpGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e2a655f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_num=4\n",
    "\n",
    "middle_layers = middle_layers_computer(X_test_value[img_num:img_num+1])\n",
    "\n",
    "for ml, name in zip(middle_layers, ['X', 'C1', 'P1', 'C2', 'P2']):\n",
    "    plot_mat(ml.transpose(1,0,2,3))\n",
    "    title(name)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
